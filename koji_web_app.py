# -*- coding: utf-8 -*-
"""
é›»å­å…¬å›³ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºWebã‚¢ãƒ—ãƒª (Streamlitç‰ˆ) - Web/GitHubå‚ç…§å¯¾å¿œ - ä¸ç›®ãƒ»å°å­—é¸æŠæ©Ÿèƒ½ä»˜ã - Webãƒ•ã‚©ãƒ«ãƒ€å¯¾å¿œ
"""

import streamlit as st
import geopandas as gpd
import pandas as pd
from shapely.geometry import Point, Polygon, MultiPolygon
import xml.etree.ElementTree as ET
from xml.dom import minidom
import zipfile
import io
import tempfile
import os
import requests
from urllib.parse import urlparse, urljoin, urlunparse
import re
from bs4 import BeautifulSoup
import json

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="é›»å­å…¬å›³ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºãƒ„ãƒ¼ãƒ«",
    page_icon="ğŸ—ºï¸",
    layout="wide"
)

class KojiWebExtractor:
    def __init__(self):
        if 'gdf' not in st.session_state:
            st.session_state.gdf = None
        if 'web_files_cache' not in st.session_state:
            st.session_state.web_files_cache = {}
    
    def get_files_from_web_folder(self, folder_url, file_extensions=None):
        """Webä¸Šã®ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—"""
        if file_extensions is None:
            file_extensions = ['.zip', '.shp']
        
        try:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒã‚§ãƒƒã‚¯
            cache_key = f"{folder_url}_{','.join(file_extensions)}"
            if cache_key in st.session_state.web_files_cache:
                return st.session_state.web_files_cache[cache_key]
            
            # GitHubã®ãƒ•ã‚©ãƒ«ãƒ€ã®å ´åˆ
            if 'github.com' in folder_url:
                return self._get_github_folder_files(folder_url, file_extensions)
            
            # é€šå¸¸ã®Webãƒ•ã‚©ãƒ«ãƒ€ã®å ´åˆ
            return self._get_generic_web_folder_files(folder_url, file_extensions)
            
        except Exception as e:
            st.error(f"ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ã®ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
            return []
    
    def _get_github_folder_files(self, folder_url, file_extensions):
        """GitHubãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—ï¼ˆGitHub APIä½¿ç”¨ + ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ï¼‰"""
        try:
            # GitHub URLã‚’è§£æ
            # https://github.com/user/repo/tree/branch/path -> GitHub API URL
            parts = folder_url.replace('https://github.com/', '').split('/')
            if len(parts) < 2:
                raise Exception("ç„¡åŠ¹ãªGitHub URLã§ã™")
            
            user = parts[0]
            repo = parts[1]
            
            # ãƒ–ãƒ©ãƒ³ãƒã¨ãƒ‘ã‚¹ã‚’ç‰¹å®š
            if len(parts) > 3 and parts[2] == 'tree':
                branch = parts[3]
                path = '/'.join(parts[4:]) if len(parts) > 4 else ''
            else:
                branch = 'main'
                path = '/'.join(parts[2:]) if len(parts) > 2 else ''
            
            # ã¾ãšAPIã‚’è©¦è¡Œã—ã€å¤±æ•—ã—ãŸå ´åˆã¯raw.githubusercontent.comã‚’ä½¿ç”¨
            try:
                # GitHub API URLæ§‹ç¯‰
                api_url = f"https://api.github.com/repos/{user}/{repo}/contents/{path}"
                if branch != 'main':
                    api_url += f"?ref={branch}"
                
                # GitHub APIãƒˆãƒ¼ã‚¯ãƒ³ãŒã‚ã‚‹å ´åˆã¯ä½¿ç”¨ï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰
                headers = {}
                github_token = os.environ.get('GITHUB_TOKEN')
                if github_token:
                    headers['Authorization'] = f'token {github_token}'
                
                response = requests.get(api_url, headers=headers, timeout=30)
                
                if response.status_code == 403:
                    # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®å ´åˆã€ä»£æ›¿æ–¹æ³•ã‚’ä½¿ç”¨
                    st.warning("âš ï¸ GitHub APIã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚ä»£æ›¿æ–¹æ³•ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ã—ã¾ã™...")
                    return self._get_github_files_alternative(user, repo, branch, path, file_extensions)
                
                response.raise_for_status()
                
                files_data = response.json()
                files = []
                
                for item in files_data:
                    if item['type'] == 'file':
                        file_name = item['name']
                        if any(file_name.lower().endswith(ext.lower()) for ext in file_extensions):
                            # rawãƒ•ã‚¡ã‚¤ãƒ«URLã‚’ç”Ÿæˆ
                            raw_url = item['download_url']
                            files.append({
                                'name': file_name,
                                'url': raw_url,
                                'size': item.get('size', 0),
                                'description': f"GitHubãƒ•ã‚¡ã‚¤ãƒ« ({item.get('size', 0)} bytes)"
                            })
                
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
                cache_key = f"{folder_url}_{','.join(file_extensions)}"
                st.session_state.web_files_cache[cache_key] = files
                
                return files
                
            except requests.exceptions.RequestException as e:
                if "403" in str(e) or "rate limit" in str(e).lower():
                    # APIãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®å ´åˆã€ä»£æ›¿æ–¹æ³•ã‚’ä½¿ç”¨
                    st.warning("âš ï¸ GitHub APIã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚ä»£æ›¿æ–¹æ³•ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ã—ã¾ã™...")
                    return self._get_github_files_alternative(user, repo, branch, path, file_extensions)
                else:
                    raise e
                
        except requests.exceptions.RequestException as e:
            raise Exception(f"GitHub APIã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼: {str(e)}")
        except json.JSONDecodeError:
            raise Exception("GitHub APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ")
        except Exception as e:
            raise Exception(f"GitHubãƒ•ã‚©ãƒ«ãƒ€å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def _get_github_files_alternative(self, user, repo, branch, path, file_extensions):
        """GitHub APIãŒä½¿ãˆãªã„å ´åˆã®ä»£æ›¿æ–¹æ³•ï¼ˆHTMLã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼‰"""
        try:
            # GitHub Webãƒšãƒ¼ã‚¸ã‹ã‚‰æƒ…å ±ã‚’å–å¾—
            web_url = f"https://github.com/{user}/{repo}/tree/{branch}/{path}"
            
            response = requests.get(web_url, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            files = []
            
            # GitHubã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒªãƒ³ã‚¯ã‚’æ¤œç´¢
            # æ–°ã—ã„GitHubUIã«å¯¾å¿œã—ãŸã‚»ãƒ¬ã‚¯ã‚¿
            file_links = soup.find_all('a', {'class': lambda x: x and 'Link--primary' in x}) if soup.find_all('a', {'class': lambda x: x and 'Link--primary' in x}) else soup.find_all('a', href=True)
            
            for link in file_links:
                href = link.get('href', '')
                link_text = link.get_text().strip()
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªãƒ³ã‚¯ã‹ãƒã‚§ãƒƒã‚¯
                if '/blob/' in href and any(link_text.lower().endswith(ext.lower()) for ext in file_extensions):
                    # raw URLã«å¤‰æ›
                    raw_url = href.replace('github.com', 'raw.githubusercontent.com').replace('/blob/', '/')
                    if not raw_url.startswith('http'):
                        raw_url = f"https://raw.githubusercontent.com{raw_url}"
                    
                    files.append({
                        'name': link_text,
                        'url': raw_url,
                        'size': None,
                        'description': f"GitHubãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆä»£æ›¿å–å¾—ï¼‰"
                    })
            
            # ã•ã‚‰ã«ä»£æ›¿æ–¹æ³•ï¼šdata-testidå±æ€§ã‚’ä½¿ç”¨
            if not files:
                file_rows = soup.find_all('div', {'data-testid': lambda x: x and 'file-row' in x}) if soup.find_all('div', {'data-testid': lambda x: x and 'file-row' in x}) else []
                
                for row in file_rows:
                    link = row.find('a', href=True)
                    if link:
                        href = link.get('href', '')
                        link_text = link.get_text().strip()
                        
                        if '/blob/' in href and any(link_text.lower().endswith(ext.lower()) for ext in file_extensions):
                            raw_url = f"https://raw.githubusercontent.com{href.replace('/blob/', '/')}"
                            
                            files.append({
                                'name': link_text,
                                'url': raw_url,
                                'size': None,
                                'description': f"GitHubãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆä»£æ›¿å–å¾—ï¼‰"
                            })
            
            # ãã‚Œã§ã‚‚è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€ã‚ˆã‚Šæ±ç”¨çš„ãªæ¤œç´¢
            if not files:
                all_links = soup.find_all('a', href=True)
                for link in all_links:
                    href = link.get('href', '')
                    link_text = link.get_text().strip()
                    
                    if ('/blob/' in href and 
                        any(ext.lower() in href.lower() or ext.lower() in link_text.lower() for ext in file_extensions)):
                        
                        if href.startswith('/'):
                            raw_url = f"https://raw.githubusercontent.com{href.replace('/blob/', '/')}"
                        else:
                            raw_url = href.replace('github.com', 'raw.githubusercontent.com').replace('/blob/', '/')
                        
                        file_name = link_text if link_text else os.path.basename(href)
                        
                        files.append({
                            'name': file_name,
                            'url': raw_url,
                            'size': None,
                            'description': f"GitHubãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆä»£æ›¿å–å¾—ï¼‰"
                        })
            
            # é‡è¤‡é™¤å»
            seen_names = set()
            unique_files = []
            for file_info in files:
                if file_info['name'] not in seen_names:
                    seen_names.add(file_info['name'])
                    unique_files.append(file_info)
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            cache_key = f"{web_url}_{','.join(file_extensions)}"
            st.session_state.web_files_cache[cache_key] = unique_files
            
            return unique_files
            
        except Exception as e:
            raise Exception(f"GitHubä»£æ›¿å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def _get_generic_web_folder_files(self, folder_url, file_extensions):
        """ä¸€èˆ¬çš„ãªWebãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—ï¼ˆHTMLãƒ‘ãƒ¼ã‚¹ï¼‰"""
        try:
            response = requests.get(folder_url, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            files = []
            
            # ãƒªãƒ³ã‚¯ã‚’æ¤œç´¢
            links = soup.find_all('a', href=True)
            
            for link in links:
                href = link['href']
                link_text = link.get_text().strip()
                
                # ç›¸å¯¾URLã‚’çµ¶å¯¾URLã«å¤‰æ›
                if not href.startswith(('http://', 'https://')):
                    href = urljoin(folder_url, href)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã‚’ãƒã‚§ãƒƒã‚¯
                if any(href.lower().endswith(ext.lower()) for ext in file_extensions):
                    # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å–å¾—
                    file_name = os.path.basename(urlparse(href).path)
                    if not file_name:
                        file_name = link_text
                    
                    files.append({
                        'name': file_name,
                        'url': href,
                        'size': None,
                        'description': f"Webãƒ•ã‚¡ã‚¤ãƒ«"
                    })
            
            # é‡è¤‡é™¤å»
            seen_urls = set()
            unique_files = []
            for file_info in files:
                if file_info['url'] not in seen_urls:
                    seen_urls.add(file_info['url'])
                    unique_files.append(file_info)
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            cache_key = f"{folder_url}_{','.join(file_extensions)}"
            st.session_state.web_files_cache[cache_key] = unique_files
            
            return unique_files
            
        except requests.exceptions.RequestException as e:
            raise Exception(f"Webãƒ•ã‚©ãƒ«ãƒ€ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼: {str(e)}")
        except Exception as e:
            raise Exception(f"Webãƒ•ã‚©ãƒ«ãƒ€å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def download_file_from_url(self, url):
        """URLã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        try:
            # GitHubã®ç”Ÿãƒ•ã‚¡ã‚¤ãƒ«URLã«å¤‰æ›
            if 'github.com' in url and '/blob/' in url:
                url = url.replace('github.com', 'raw.githubusercontent.com').replace('/blob/', '/')
            
            response = requests.get(url, timeout=30)
            response.raise_for_status()
            
            return io.BytesIO(response.content)
            
        except requests.exceptions.RequestException as e:
            raise Exception(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
    
    def load_shapefile_from_url(self, url):
        """URLã‹ã‚‰Shapefileã‚’èª­ã¿è¾¼ã¿"""
        try:
            file_obj = self.download_file_from_url(url)
            
            with tempfile.TemporaryDirectory() as temp_dir:
                # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦å±•é–‹ã‚’è©¦è¡Œ
                try:
                    with zipfile.ZipFile(file_obj, 'r') as zip_ref:
                        zip_ref.extractall(temp_dir)
                    
                    # SHPãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
                    shp_files = [f for f in os.listdir(temp_dir) if f.endswith('.shp')]
                    
                    if shp_files:
                        shp_path = os.path.join(temp_dir, shp_files[0])
                        return gpd.read_file(shp_path)
                    else:
                        raise Exception("ZIPãƒ•ã‚¡ã‚¤ãƒ«å†…ã«SHPãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                        
                except zipfile.BadZipFile:
                    # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã§ãªã„å ´åˆã€ç›´æ¥SHPãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦èª­ã¿è¾¼ã¿ã‚’è©¦è¡Œ
                    file_obj.seek(0)  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚¤ãƒ³ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ
                    
                    # ä¸€æ™‚çš„ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
                    temp_file = os.path.join(temp_dir, "temp_file")
                    with open(temp_file, 'wb') as f:
                        f.write(file_obj.read())
                    
                    # æ‹¡å¼µå­ã‚’æ¨æ¸¬ã—ã¦ãƒªãƒãƒ¼ãƒ 
                    if url.lower().endswith('.shp'):
                        shp_file = temp_file + '.shp'
                        os.rename(temp_file, shp_file)
                        return gpd.read_file(shp_file)
                    else:
                        return gpd.read_file(temp_file)
                        
        except Exception as e:
            raise Exception(f"Shapefileã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
    
    def create_kml_from_geodataframe(self, gdf, name="åœ°ç•ªãƒ‡ãƒ¼ã‚¿"):
        """GeoPandasãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰KMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆï¼ˆåº§æ¨™å¤‰æ›ä»˜ãï¼‰"""
        try:
            # WGS84ï¼ˆç·¯åº¦çµŒåº¦ï¼‰ã«åº§æ¨™å¤‰æ›
            gdf_wgs84 = gdf.to_crs(epsg=4326)
            
            # KMLã®ãƒ«ãƒ¼ãƒˆè¦ç´ ã‚’ä½œæˆ
            kml = ET.Element("kml", xmlns="http://www.opengis.net/kml/2.2")
            document = ET.SubElement(kml, "Document")
            doc_name = ET.SubElement(document, "name")
            doc_name.text = name
            
            # ã‚¹ã‚¿ã‚¤ãƒ«ã‚’å®šç¾©
            style = ET.SubElement(document, "Style", id="PolygonStyle")
            line_style = ET.SubElement(style, "LineStyle")
            line_color = ET.SubElement(line_style, "color")
            line_color.text = "ff0000ff"  # èµ¤è‰²
            line_width = ET.SubElement(line_style, "width")
            line_width.text = "2"
            
            poly_style = ET.SubElement(style, "PolyStyle")
            poly_color = ET.SubElement(poly_style, "color")
            poly_color.text = "3300ff00"  # åŠé€æ˜ç·‘
            
            # å„ãƒ¬ã‚³ãƒ¼ãƒ‰ã«å¯¾ã—ã¦Placemarkã‚’ä½œæˆ
            for idx, row in gdf_wgs84.iterrows():
                placemark = ET.SubElement(document, "Placemark")
                
                # åå‰ã‚’è¨­å®š
                pm_name = ET.SubElement(placemark, "name")
                if 'åœ°ç•ª' in row:
                    pm_name.text = str(row['åœ°ç•ª'])
                else:
                    pm_name.text = f"åœ°ç•ª_{idx}"
                
                # èª¬æ˜ã‚’è¨­å®š
                description = ET.SubElement(placemark, "description")
                desc_text = ""
                for col in gdf_wgs84.columns:
                    if col != 'geometry':
                        desc_text += f"{col}: {row[col]}<br/>"
                description.text = desc_text
                
                # ã‚¹ã‚¿ã‚¤ãƒ«ã‚’é©ç”¨
                style_url = ET.SubElement(placemark, "styleUrl")
                style_url.text = "#PolygonStyle"
                
                # ã‚¸ã‚ªãƒ¡ãƒˆãƒªã‚’å‡¦ç†
                geom = row['geometry']
                if geom.geom_type == 'Polygon':
                    self._add_polygon_to_placemark(placemark, geom)
                elif geom.geom_type == 'MultiPolygon':
                    for poly in geom.geoms:
                        self._add_polygon_to_placemark(placemark, poly)
                elif geom.geom_type == 'Point':
                    self._add_point_to_placemark(placemark, geom)
            
            # XMLã‚’æ•´å½¢ã—ã¦æ–‡å­—åˆ—ã¨ã—ã¦è¿”ã™
            rough_string = ET.tostring(kml, 'unicode')
            reparsed = minidom.parseString(rough_string)
            pretty_xml = reparsed.toprettyxml(indent="  ")
            
            return pretty_xml
            
        except Exception as e:
            st.error(f"KMLä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def _add_polygon_to_placemark(self, placemark, polygon):
        """Polygonã‚’Placemarkã«è¿½åŠ """
        multigeometry = placemark.find("MultiGeometry")
        if multigeometry is None:
            multigeometry = ET.SubElement(placemark, "MultiGeometry")
        
        kml_polygon = ET.SubElement(multigeometry, "Polygon")
        
        # å¤–ç’°ã‚’è¿½åŠ 
        outer_boundary = ET.SubElement(kml_polygon, "outerBoundaryIs")
        linear_ring = ET.SubElement(outer_boundary, "LinearRing")
        coordinates = ET.SubElement(linear_ring, "coordinates")
        
        # åº§æ¨™ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
        coord_str = ""
        for x, y in polygon.exterior.coords:
            coord_str += f"{x},{y},0 "
        coordinates.text = coord_str.strip()
        
        # å†…ç’°ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
        for interior in polygon.interiors:
            inner_boundary = ET.SubElement(kml_polygon, "innerBoundaryIs")
            inner_ring = ET.SubElement(inner_boundary, "LinearRing")
            inner_coordinates = ET.SubElement(inner_ring, "coordinates")
            
            inner_coord_str = ""
            for x, y in interior.coords:
                inner_coord_str += f"{x},{y},0 "
            inner_coordinates.text = inner_coord_str.strip()
    
    def _add_point_to_placemark(self, placemark, point):
        """Pointã‚’Placemarkã«è¿½åŠ """
        kml_point = ET.SubElement(placemark, "Point")
        coordinates = ET.SubElement(kml_point, "coordinates")
        coordinates.text = f"{point.x},{point.y},0"
    
    def extract_data(self, gdf, oaza, chome, koaza, chiban, range_m):
        """ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºå‡¦ç†ï¼ˆä¸ç›®ãƒ»å°å­—å¯¾å¿œï¼‰"""
        try:
            # å¿…è¦ãªåˆ—ã®å­˜åœ¨ç¢ºèª
            required_columns = ['å¤§å­—å', 'åœ°ç•ª']
            missing_columns = [col for col in required_columns if col not in gdf.columns]
            
            if missing_columns:
                return None, None, f"å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing_columns}"
            
            # NULLå€¤ã‚’ãƒã‚§ãƒƒã‚¯
            null_check = {}
            for col in required_columns:
                null_count = gdf[col].isnull().sum()
                if null_count > 0:
                    null_check[col] = null_count
            
            if null_check:
                warning_msg = "è­¦å‘Š: NULLå€¤ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ - " + ", ".join([f"{k}: {v}ä»¶" for k, v in null_check.items()])
                st.warning(warning_msg)
            
            # æ¤œç´¢æ¡ä»¶ã‚’æ§‹ç¯‰ï¼ˆä¸ç›®ãƒ»å°å­—ã®æœ‰ç„¡ã«å¿œã˜ã¦ï¼‰
            search_condition = (
                (gdf['å¤§å­—å'] == oaza) & 
                (gdf['åœ°ç•ª'] == chiban) &
                (gdf['å¤§å­—å'].notna()) &
                (gdf['åœ°ç•ª'].notna())
            )
            
            # ä¸ç›®ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯æ¡ä»¶ã«è¿½åŠ 
            if chome is not None and chome != "é¸æŠãªã—" and 'ä¸ç›®å' in gdf.columns:
                search_condition = search_condition & (gdf['ä¸ç›®å'] == chome) & (gdf['ä¸ç›®å'].notna())
            
            # å°å­—ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯æ¡ä»¶ã«è¿½åŠ 
            if koaza is not None and koaza != "é¸æŠãªã—" and 'å°å­—å' in gdf.columns:
                search_condition = search_condition & (gdf['å°å­—å'] == koaza) & (gdf['å°å­—å'].notna())
            
            df = gdf[search_condition]
            
            if df.empty:
                # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’æä¾›
                debug_info = []
                oaza_matches = gdf[gdf['å¤§å­—å'] == oaza]['å¤§å­—å'].count()
                chiban_matches = gdf[gdf['åœ°ç•ª'] == chiban]['åœ°ç•ª'].count()
                
                debug_info.append(f"å¤§å­—å'{oaza}'ã®è©²å½“ä»¶æ•°: {oaza_matches}")
                debug_info.append(f"åœ°ç•ª'{chiban}'ã®è©²å½“ä»¶æ•°: {chiban_matches}")
                
                if chome and chome != "é¸æŠãªã—" and 'ä¸ç›®å' in gdf.columns:
                    chome_matches = gdf[gdf['ä¸ç›®å'] == chome]['ä¸ç›®å'].count()
                    debug_info.append(f"ä¸ç›®å'{chome}'ã®è©²å½“ä»¶æ•°: {chome_matches}")
                
                if koaza and koaza != "é¸æŠãªã—" and 'å°å­—å' in gdf.columns:
                    koaza_matches = gdf[gdf['å°å­—å'] == koaza]['å°å­—å'].count()
                    debug_info.append(f"å°å­—å'{koaza}'ã®è©²å½“ä»¶æ•°: {koaza_matches}")
                
                return None, None, f"è©²å½“ã™ã‚‹ç­†ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚{' / '.join(debug_info)}"
            
            # åˆ©ç”¨å¯èƒ½ãªåˆ—ã®ã¿ã‚’é¸æŠ
            available_columns = ["å¤§å­—å", "åœ°ç•ª", "geometry"]
            if "ä¸ç›®å" in gdf.columns:
                available_columns.insert(1, "ä¸ç›®å")
            if "å°å­—å" in gdf.columns:
                insert_position = 2 if "ä¸ç›®å" in available_columns else 1
                available_columns.insert(insert_position, "å°å­—å")
            
            # å­˜åœ¨ã™ã‚‹åˆ—ã®ã¿ã§ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
            existing_columns = [col for col in available_columns if col in df.columns]
            df_summary = df.reindex(columns=existing_columns)
            
            # geometryã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã—ã€æœ‰åŠ¹ã‹ãƒã‚§ãƒƒã‚¯
            if 'geometry' not in df_summary.columns:
                return None, None, "geometryåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            
            if df_summary['geometry'].isnull().any():
                return None, None, "geometryåˆ—ã«NULLå€¤ãŒå«ã¾ã‚Œã¦ã„ã¾ã™"
            
            # ä¸­å¿ƒç‚¹è¨ˆç®—ã¨å‘¨è¾ºç­†æŠ½å‡º
            cen = df_summary.geometry.centroid
            
            cen_gdf = gpd.GeoDataFrame(geometry=cen)
            cen_gdf['x'] = cen_gdf.geometry.x
            cen_gdf['y'] = cen_gdf.geometry.y
            
            # æ¤œç´¢ç¯„å›²ã®4è§’ãƒã‚¤ãƒ³ãƒˆè¨ˆç®—
            i1 = cen_gdf['x'] + range_m
            i2 = cen_gdf['x'] - range_m
            i3 = cen_gdf['y'] + range_m
            i4 = cen_gdf['y'] - range_m
            
            x1, y1 = i3.iloc[0], i1.iloc[0]
            x2, y2 = i4.iloc[0], i2.iloc[0]
            
            # 4ã¤ã®ãƒã‚¤ãƒ³ãƒˆã‚’å®šç¾©
            top_right = [x1, y1]
            lower_left = [x2, y2]
            lower_right = [x1, y2]
            top_left = [x2, y1]
            
            points = pd.DataFrame([top_right, lower_left, lower_right, top_left],
                                index=["top_right", "lower_left", "lower_right", "top_left"],
                                columns=["lon", "lat"])
            
            # ã‚¸ã‚ªãƒ¡ãƒˆãƒªä½œæˆ
            geometry = [Point(xy) for xy in zip(points.lat, points.lon)]
            four_points_gdf = gpd.GeoDataFrame(points, geometry=geometry)
            
            # æ¤œç´¢ç¯„å›²ã®ãƒãƒªã‚´ãƒ³ä½œæˆ
            sq = four_points_gdf.dissolve().convex_hull
            
            # ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤å‡¦ç†ï¼ˆNULLå€¤ã‚’é™¤å¤–ã—ãŸãƒ‡ãƒ¼ã‚¿ã§ï¼‰
            df1 = gpd.GeoDataFrame({'geometry': sq})
            df1 = df1.set_crs(gdf.crs)
            
            # åœ°ç•ªã¨geometryãŒä¸¡æ–¹ã¨ã‚‚æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ä½¿ç”¨
            valid_data = gdf[(gdf['åœ°ç•ª'].notna()) & (gdf['geometry'].notna())].copy()
            
            # å‘¨è¾ºç­†æŠ½å‡ºç”¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆï¼ˆåˆ©ç”¨å¯èƒ½ãªåˆ—ã®ã¿ä½¿ç”¨ï¼‰
            overlay_columns = ['åœ°ç•ª', 'geometry']
            if 'å¤§å­—å' in valid_data.columns:
                overlay_columns.insert(0, 'å¤§å­—å')
            if 'ä¸ç›®å' in valid_data.columns:
                overlay_columns.insert(-1, 'ä¸ç›®å')
            if 'å°å­—å' in valid_data.columns:
                overlay_columns.insert(-1, 'å°å­—å')
            
            existing_overlay_columns = [col for col in overlay_columns if col in valid_data.columns]
            df2 = gpd.GeoDataFrame(valid_data[existing_overlay_columns])
            
            overlay_gdf = df1.overlay(df2, how='intersection')
            
            return df_summary, overlay_gdf, f"å¯¾è±¡ç­†: {len(df_summary)}ä»¶, å‘¨è¾ºç­†: {len(overlay_gdf)}ä»¶"
            
        except Exception as e:
            return None, None, f"ã‚¨ãƒ©ãƒ¼: {str(e)}")

def get_chome_options(gdf, selected_oaza):
    """æŒ‡å®šã•ã‚ŒãŸå¤§å­—åã«å¯¾å¿œã™ã‚‹ä¸ç›®ã®é¸æŠè‚¢ã‚’å–å¾—"""
    try:
        if 'ä¸ç›®å' not in gdf.columns:
            return None
        
        # æŒ‡å®šã•ã‚ŒãŸå¤§å­—åã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        filtered_gdf = gdf[
            (gdf['å¤§å­—å'] == selected_oaza) & 
            (gdf['å¤§å­—å'].notna()) &
            (gdf['ä¸ç›®å'].notna())
        ]
        
        if len(filtered_gdf) == 0:
            return None
        
        # ä¸ç›®åã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ã‚’å–å¾—ã—ã¦ã‚½ãƒ¼ãƒˆ
        chome_list = sorted(filtered_gdf['ä¸ç›®å'].unique())
        
        return chome_list
        
    except Exception as e:
        st.error(f"ä¸ç›®åå–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None

def get_koaza_options(gdf, selected_oaza, selected_chome=None):
    """æŒ‡å®šã•ã‚ŒãŸå¤§å­—åï¼ˆåŠã³ä¸ç›®åï¼‰ã«å¯¾å¿œã™ã‚‹å°å­—ã®é¸æŠè‚¢ã‚’å–å¾—"""
    try:
        if 'å°å­—å' not in gdf.columns:
            return None
        
        # ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã‚’æ§‹ç¯‰
        filter_condition = (
            (gdf['å¤§å­—å'] == selected_oaza) & 
            (gdf['å¤§å­—å'].notna()) &
            (gdf['å°å­—å'].notna())
        )
        
        # ä¸ç›®ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯æ¡ä»¶ã«è¿½åŠ 
        if selected_chome and selected_chome != "é¸æŠãªã—" and 'ä¸ç›®å' in gdf.columns:
            filter_condition = filter_condition & (gdf['ä¸ç›®å'] == selected_chome) & (gdf['ä¸ç›®å'].notna())
        
        # æŒ‡å®šã•ã‚ŒãŸæ¡ä»¶ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        filtered_gdf = gdf[filter_condition]
        
        if len(filtered_gdf) == 0:
            return None
        
        # å°å­—åã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ã‚’å–å¾—ã—ã¦ã‚½ãƒ¼ãƒˆ
        koaza_list = sorted(filtered_gdf['å°å­—å'].unique())
        
        return koaza_list
        
    except Exception as e:
        st.error(f"å°å­—åå–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None

def main():
    st.title("ğŸ—ºï¸ é›»å­å…¬å›³ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºãƒ„ãƒ¼ãƒ«")
    st.markdown("---")
    
    extractor = KojiWebExtractor()
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    st.sidebar.header("ğŸ“‹ ãƒ—ãƒªã‚»ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«")
    
    # Webãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ã®ãƒ—ãƒªã‚»ãƒƒãƒˆé¸æŠ
    st.sidebar.subheader("ğŸŒ Webãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ã®ãƒ—ãƒªã‚»ãƒƒãƒˆ")
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®Webãƒ•ã‚©ãƒ«ãƒ€URLï¼ˆä¾‹ï¼‰
    default_folder_urls = [
        "https://github.com/example/geodata/tree/main/shapefiles",
        "https://data.example.com/shapefiles/",
        "https://github.com/your-org/survey-data/tree/main/data"
    ]
    
    # ã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚©ãƒ«ãƒ€URLå…¥åŠ›
    custom_folder_url = st.sidebar.text_input(
        "ã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚©ãƒ«ãƒ€URL",
        placeholder="https://github.com/user/repo/tree/main/data",
        help="ShapefileãŒæ ¼ç´ã•ã‚Œã¦ã„ã‚‹Webãƒ•ã‚©ãƒ«ãƒ€ã®URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
    )
    
    # ãƒ•ã‚©ãƒ«ãƒ€URLé¸æŠ
    folder_options = ["ã‚«ã‚¹ã‚¿ãƒ "] + [f"ã‚µãƒ³ãƒ—ãƒ«{i+1}" for i in range(len(default_folder_urls))]
    selected_folder_option = st.sidebar.selectbox(
        "ãƒ•ã‚©ãƒ«ãƒ€ã‚’é¸æŠ",
        folder_options,
        help="ãƒ—ãƒªã‚»ãƒƒãƒˆãƒ•ã‚©ãƒ«ãƒ€ã¾ãŸã¯ã‚«ã‚¹ã‚¿ãƒ URLã‚’é¸æŠ"
    )
    
    # é¸æŠã•ã‚ŒãŸãƒ•ã‚©ãƒ«ãƒ€URLã‚’æ±ºå®š
    if selected_folder_option == "ã‚«ã‚¹ã‚¿ãƒ ":
        folder_url = custom_folder_url
    else:
        folder_index = int(selected_folder_option.replace("ã‚µãƒ³ãƒ—ãƒ«", "")) - 1
        folder_url = default_folder_urls[folder_index]
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
    web_files = []
    if folder_url:
        if st.sidebar.button("ğŸ“‚ ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—", type="secondary"):
            with st.spinner("Webãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—ä¸­..."):
                try:
                    web_files = extractor.get_files_from_web_folder(folder_url)
                except Exception as e:
                    if "rate limit" in str(e).lower() or "403" in str(e):
                        st.sidebar.error("âŒ GitHub APIã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
                        st.sidebar.info("ğŸ’¡ ãƒ’ãƒ³ãƒˆ: GitHubãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç’°å¢ƒå¤‰æ•° 'GITHUB_TOKEN' ã«è¨­å®šã™ã‚‹ã¨åˆ¶é™ãŒç·©å’Œã•ã‚Œã¾ã™ã€‚")
                    else:
                        st.sidebar.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    web_files = []
            
            if web_files:
                st.sidebar.success(f"âœ… {len(web_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                st.session_state.current_web_files = web_files
                st.session_state.current_folder_url = folder_url
            else:
                st.sidebar.warning("âŒ å¯¾å¿œãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’ä½¿ç”¨
    if 'current_web_files' in st.session_state:
        web_files = st.session_state.current_web_files
        
        if web_files:
            st.sidebar.write(f"**ğŸ“ {st.session_state.current_folder_url}**")
            st.sidebar.write(f"åˆ©ç”¨å¯èƒ½ãƒ•ã‚¡ã‚¤ãƒ«: {len(web_files)}å€‹")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ
            file_options = ["é¸æŠãªã—"] + [f["name"] for f in web_files]
            selected_file = st.sidebar.selectbox(
                "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
                file_options,
                help="èª­ã¿è¾¼ã‚€Shapefileã‚’é¸æŠã—ã¦ãã ã•ã„"
            )
            
            if selected_file != "é¸æŠãªã—":
                # é¸æŠã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°ã‚’è¡¨ç¤º
                selected_file_info = next((f for f in web_files if f["name"] == selected_file), None)
                if selected_file_info:
                    st.sidebar.info(f"**{selected_file_info['name']}**\n\n{selected_file_info['description']}")
                    
                    if st.sidebar.button("ğŸ“¥ é¸æŠãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿", type="primary"):
                        try:
                            with st.spinner(f"ãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{selected_file}ã€ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
                                st.session_state.gdf = extractor.load_shapefile_from_url(selected_file_info['url'])
                            
                            st.sidebar.success("âœ… ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†!")
                            st.sidebar.info(f"ğŸ“Š ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(st.session_state.gdf):,}ä»¶")
                            
                            if st.session_state.gdf.crs:
                                st.sidebar.info(f"ğŸ—ºï¸ åº§æ¨™ç³»: {st.session_state.gdf.crs}")
                            
                            # ä¸ç›®åãƒ»å°å­—ååˆ—ã®å­˜åœ¨ç¢ºèª
                            if 'ä¸ç›®å' in st.session_state.gdf.columns:
                                chome_count = st.session_state.gdf['ä¸ç›®å'].notna().sum()
                                st.sidebar.info(f"ğŸ˜ï¸ ä¸ç›®ãƒ‡ãƒ¼ã‚¿: {chome_count}ä»¶")
                            
                            if 'å°å­—å' in st.session_state.gdf.columns:
                                koaza_count = st.session_state.gdf['å°å­—å'].notna().sum()
                                st.sidebar.info(f"ğŸï¸ å°å­—ãƒ‡ãƒ¼ã‚¿: {koaza_count}ä»¶")
                            
                            # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æƒ…å ±ã‚’è¨˜éŒ²
                            st.session_state.data_source = "Webãƒ•ã‚©ãƒ«ãƒ€"
                            st.session_state.current_preset = selected_file
                            st.session_state.file_info = selected_file_info['url']
                                
                        except Exception as e:
                            st.sidebar.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    # å¾“æ¥ã®ãƒ—ãƒªã‚»ãƒƒãƒˆæ©Ÿèƒ½ï¼ˆå›ºå®šãƒªã‚¹ãƒˆï¼‰
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ“‹ å›ºå®šãƒ—ãƒªã‚»ãƒƒãƒˆ")
    
    # ãƒ—ãƒªã‚»ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«æ©Ÿèƒ½
    preset_files = {
        "ã‚µãƒ³ãƒ—ãƒ«1": {
            "name": "æ±äº¬éƒ½ã‚µãƒ³ãƒ—ãƒ«åœ°ç•ªãƒ‡ãƒ¼ã‚¿",
            "url": "https://example.com/tokyo_sample.zip",
            "description": "æ±äº¬éƒ½ã®åœ°ç•ªãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«ï¼ˆä¸ç›®ãƒ»å°å­—å¯¾å¿œï¼‰"
        },
        "ã‚µãƒ³ãƒ—ãƒ«2": {
            "name": "å¤§é˜ªåºœã‚µãƒ³ãƒ—ãƒ«åœ°ç•ªãƒ‡ãƒ¼ã‚¿", 
            "url": "https://example.com/osaka_sample.zip",
            "description": "å¤§é˜ªåºœã®åœ°ç•ªãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«ï¼ˆå°å­—å¯¾å¿œï¼‰"
        },
        "ã‚µãƒ³ãƒ—ãƒ«3": {
            "name": "åŸºæœ¬åœ°ç•ªãƒ‡ãƒ¼ã‚¿",
            "url": "https://example.com/basic_sample.zip", 
            "description": "åŸºæœ¬çš„ãªåœ°ç•ªãƒ‡ãƒ¼ã‚¿ï¼ˆå¤§å­—åãƒ»åœ°ç•ªã®ã¿ï¼‰"
        }
    }
    
    # ãƒ—ãƒªã‚»ãƒƒãƒˆé¸æŠ
    selected_preset = st.sidebar.selectbox(
        "å›ºå®šãƒ—ãƒªã‚»ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
        ["é¸æŠãªã—"] + list(preset_files.keys()),
        help="äº‹å‰ã«è¨­å®šã•ã‚ŒãŸã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰é¸æŠã§ãã¾ã™"
    )
    
    if selected_preset != "é¸æŠãªã—":
        preset_info = preset_files[selected_preset]
        st.sidebar.info(f"**{preset_info['name']}**\n\n{preset_info['description']}")
        
        if st.sidebar.button("ğŸ“‹ å›ºå®šãƒ—ãƒªã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿", type="secondary"):
            try:
                with st.spinner(f"ãƒ—ãƒªã‚»ãƒƒãƒˆã€Œ{selected_preset}ã€ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
                    st.session_state.gdf = extractor.load_shapefile_from_url(preset_info['url'])
                
                st.sidebar.success("âœ… ãƒ—ãƒªã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿å®Œäº†!")
                st.sidebar.info(f"ğŸ“Š ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(st.session_state.gdf):,}ä»¶")
                
                if st.session_state.gdf.crs:
                    st.sidebar.info(f"ğŸ—ºï¸ åº§æ¨™ç³»: {st.session_state.gdf.crs}")
                
                # ä¸ç›®åãƒ»å°å­—ååˆ—ã®å­˜åœ¨ç¢ºèª
                if 'ä¸ç›®å' in st.session_state.gdf.columns:
                    chome_count = st.session_state.gdf['ä¸ç›®å'].notna().sum()
                    st.sidebar.info(f"ğŸ˜ï¸ ä¸ç›®ãƒ‡ãƒ¼ã‚¿: {chome_count}ä»¶")
                
                if 'å°å­—å' in st.session_state.gdf.columns:
                    koaza_count = st.session_state.gdf['å°å­—å'].notna().sum()
                    st.sidebar.info(f"ğŸï¸ å°å­—ãƒ‡ãƒ¼ã‚¿: {koaza_count}ä»¶")
                
                # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æƒ…å ±ã‚’è¨˜éŒ²
                st.session_state.data_source = "å›ºå®šãƒ—ãƒªã‚»ãƒƒãƒˆ"
                st.session_state.current_preset = selected_preset
                st.session_state.file_info = preset_info['name']
                    
            except Exception as e:
                st.sidebar.error(f"âŒ ãƒ—ãƒªã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    st.sidebar.markdown("---")
    st.sidebar.header("ğŸ“‚ ç‹¬è‡ªãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹é¸æŠ")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹é¸æŠ
    data_source = st.sidebar.radio(
        "ç‹¬è‡ªãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’é¸æŠ",
        ["ğŸ“ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«", "ğŸŒ Web URL", "ğŸ™ GitHub"],
        help="ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã®å–å¾—æ–¹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„"
    )
    
    if data_source == "ğŸ“ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«":
        # å¾“æ¥ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        uploaded_file = st.sidebar.file_uploader(
            "SHPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=['zip'],
            help="SHPãƒ•ã‚¡ã‚¤ãƒ«ä¸€å¼ã‚’ZIPã§åœ§ç¸®ã—ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"
        )
        
        if uploaded_file is not None:
            try:
                with tempfile.TemporaryDirectory() as temp_dir:
                    # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’å±•é–‹
                    with zipfile.ZipFile(uploaded_file, 'r') as zip_ref:
                        zip_ref.extractall(temp_dir)
                    
                    # SHPãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
                    shp_files = [f for f in os.listdir(temp_dir) if f.endswith('.shp')]
                    
                    if shp_files:
                        shp_path = os.path.join(temp_dir, shp_files[0])
                        st.session_state.gdf = gpd.read_file(shp_path)
                        
                        st.sidebar.success("âœ… ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†!")
                        st.sidebar.info(f"ğŸ“Š ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(st.session_state.gdf):,}ä»¶")
                        
                        # åº§æ¨™å‚ç…§ç³»ã®ç¢ºèª
                        if st.session_state.gdf.crs:
                            st.sidebar.info(f"ğŸ—ºï¸ åº§æ¨™ç³»: {st.session_state.gdf.crs}")
                        
                        # ä¸ç›®åãƒ»å°å­—ååˆ—ã®å­˜åœ¨ç¢ºèª
                        if 'ä¸ç›®å' in st.session_state.gdf.columns:
                            chome_count = st.session_state.gdf['ä¸ç›®å'].notna().sum()
                            st.sidebar.info(f"ğŸ˜ï¸ ä¸ç›®ãƒ‡ãƒ¼ã‚¿: {chome_count}ä»¶")
                        
                        if 'å°å­—å' in st.session_state.gdf.columns:
                            koaza_count = st.session_state.gdf['å°å­—å'].notna().sum()
                            st.sidebar.info(f"ğŸï¸ å°å­—ãƒ‡ãƒ¼ã‚¿: {koaza_count}ä»¶")
                        
                        # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æƒ…å ±ã‚’è¨˜éŒ²
                        st.session_state.data_source = "ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«"
                        st.session_state.file_info = uploaded_file.name
                        if 'current_preset' in st.session_state:
                            del st.session_state.current_preset
                    else:
                        st.sidebar.error("âŒ SHPãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                        
            except Exception as e:
                st.sidebar.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    elif data_source == "ğŸŒ Web URL":
        # Web URLå…¥åŠ›
        web_url = st.sidebar.text_input(
            "ãƒ•ã‚¡ã‚¤ãƒ«ã®URL",
            placeholder="https://example.com/data.zip",
            help="ZIPãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯SHPãƒ•ã‚¡ã‚¤ãƒ«ã®ç›´æ¥URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
        )
        
        if st.sidebar.button("ğŸŒ URLã‹ã‚‰èª­ã¿è¾¼ã¿", type="primary"):
            if web_url:
                try:
                    with st.spinner("URLã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
                        st.session_state.gdf = extractor.load_shapefile_from_url(web_url)
                    
                    st.sidebar.success("âœ… ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†!")
                    st.sidebar.info(f"ğŸ“Š ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(st.session_state.gdf):,}ä»¶")
                    
                    if st.session_state.gdf.crs:
                        st.sidebar.info(f"ğŸ—ºï¸ åº§æ¨™ç³»: {st.session_state.gdf.crs}")
                    
                    # ä¸ç›®åãƒ»å°å­—ååˆ—ã®å­˜åœ¨ç¢ºèª
                    if 'ä¸ç›®å' in st.session_state.gdf.columns:
                        chome_count = st.session_state.gdf['ä¸ç›®å'].notna().sum()
                        st.sidebar.info(f"ğŸ˜ï¸ ä¸ç›®ãƒ‡ãƒ¼ã‚¿: {chome_count}ä»¶")
                    
                    if 'å°å­—å' in st.session_state.gdf.columns:
                        koaza_count = st.session_state.gdf['å°å­—å'].notna().sum()
                        st.sidebar.info(f"ğŸï¸ å°å­—ãƒ‡ãƒ¼ã‚¿: {koaza_count}ä»¶")
                    
                    # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æƒ…å ±ã‚’è¨˜éŒ²
                    st.session_state.data_source = "Web URL"
                    st.session_state.file_info = web_url
                    if 'current_preset' in st.session_state:
                        del st.session_state.current_preset
                        
                except Exception as e:
                    st.sidebar.error(f"âŒ {str(e)}")
            else:
                st.sidebar.error("URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    
    elif data_source == "ğŸ™ GitHub":
        # GitHub URLå…¥åŠ›
        col_owner, col_repo = st.sidebar.columns(2)
        with col_owner:
            github_owner = st.text_input("GitHubãƒ¦ãƒ¼ã‚¶ãƒ¼å", placeholder="username")
        with col_repo:
            github_repo = st.text_input("ãƒªãƒã‚¸ãƒˆãƒªå", placeholder="repository")
        
        github_path = st.sidebar.text_input(
            "ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹",
            placeholder="data/shapefile.zip",
            help="ãƒªãƒã‚¸ãƒˆãƒªå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
        )
        
        github_branch = st.sidebar.text_input("ãƒ–ãƒ©ãƒ³ãƒå", value="main")
        
        if st.sidebar.button("ğŸ™ GitHubã‹ã‚‰èª­ã¿è¾¼ã¿", type="primary"):
            if github_owner and github_repo and github_path:
                try:
                    github_url = f"https://github.com/{github_owner}/{github_repo}/blob/{github_branch}/{github_path}"
                    
                    with st.spinner("GitHubã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
                        st.session_state.gdf = extractor.load_shapefile_from_url(github_url)
                    
                    st.sidebar.success("âœ… ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†!")
                    st.sidebar.info(f"ğŸ“Š ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(st.session_state.gdf):,}ä»¶")
                    
                    if st.session_state.gdf.crs:
                        st.sidebar.info(f"ğŸ—ºï¸ åº§æ¨™ç³»: {st.session_state.gdf.crs}")
                    
                    # ä¸ç›®åãƒ»å°å­—ååˆ—ã®å­˜åœ¨ç¢ºèª
                    if 'ä¸ç›®å' in st.session_state.gdf.columns:
                        chome_count = st.session_state.gdf['ä¸ç›®å'].notna().sum()
                        st.sidebar.info(f"ğŸ˜ï¸ ä¸ç›®ãƒ‡ãƒ¼ã‚¿: {chome_count}ä»¶")
                    
                    if 'å°å­—å' in st.session_state.gdf.columns:
                        koaza_count = st.session_state.gdf['å°å­—å'].notna().sum()
                        st.sidebar.info(f"ğŸï¸ å°å­—ãƒ‡ãƒ¼ã‚¿: {koaza_count}ä»¶")
                    
                    # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æƒ…å ±ã‚’è¨˜éŒ²
                    st.session_state.data_source = "GitHub"
                    st.session_state.file_info = github_url
                    if 'current_preset' in st.session_state:
                        del st.session_state.current_preset
                        
                except Exception as e:
                    st.sidebar.error(f"âŒ {str(e)}")
            else:
                st.sidebar.error("GitHubã®æƒ…å ±ã‚’ã™ã¹ã¦å…¥åŠ›ã—ã¦ãã ã•ã„")
    
    # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
    if st.session_state.gdf is not None:
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.header("ğŸ” æ¤œç´¢æ¡ä»¶")
            
            # å¤§å­—åé¸æŠï¼ˆãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ï¼‰
            selected_oaza = None
            try:
                if 'å¤§å­—å' in st.session_state.gdf.columns:
                    # NULLå€¤ã‚’é™¤å¤–ã—ã¦ã‚½ãƒ¼ãƒˆ
                    oaza_series = st.session_state.gdf['å¤§å­—å'].dropna()
                    if len(oaza_series) > 0:
                        oaza_list = sorted(oaza_series.unique())
                        selected_oaza = st.selectbox("å¤§å­—åã‚’é¸æŠ", oaza_list)
                    else:
                        st.error("âŒ å¤§å­—åãƒ‡ãƒ¼ã‚¿ãŒã™ã¹ã¦NULLã§ã™")
                        selected_oaza = None
                else:
                    st.error("âŒ 'å¤§å­—å'åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                    st.write("**åˆ©ç”¨å¯èƒ½ãªåˆ—:**", list(st.session_state.gdf.columns))
                    selected_oaza = None
            except Exception as e:
                st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
                selected_oaza = None
            
            # ä¸ç›®åé¸æŠï¼ˆå¤§å­—åãŒé¸æŠã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿ï¼‰
            selected_chome = None
            if selected_oaza is not None:
                chome_options = get_chome_options(st.session_state.gdf, selected_oaza)
                
                if chome_options is not None and len(chome_options) > 0:
                    # ä¸ç›®é¸æŠè‚¢ãŒã‚ã‚‹å ´åˆ
                    chome_list_with_none = ["é¸æŠãªã—"] + chome_options
                    selected_chome = st.selectbox(
                        "ä¸ç›®åã‚’é¸æŠï¼ˆä»»æ„ï¼‰", 
                        chome_list_with_none,
                        help="ä¸ç›®ã‚’æŒ‡å®šã™ã‚‹å ´åˆã¯é¸æŠã—ã¦ãã ã•ã„ã€‚æŒ‡å®šã—ãªã„å ´åˆã¯ã€Œé¸æŠãªã—ã€ã®ã¾ã¾ã«ã—ã¦ãã ã•ã„ã€‚"
                    )
                    
                    if selected_chome == "é¸æŠãªã—":
                        st.info("ğŸ’¡ ä¸ç›®ã‚’æŒ‡å®šã›ãšã«æ¤œç´¢ã—ã¾ã™")
                    else:
                        st.success(f"âœ… ä¸ç›®ã€Œ{selected_chome}ã€ã‚’æŒ‡å®šã—ã¾ã—ãŸ")
                        
                elif 'ä¸ç›®å' in st.session_state.gdf.columns:
                    # ä¸ç›®ååˆ—ã¯å­˜åœ¨ã™ã‚‹ãŒã€ã“ã®å¤§å­—åã«ã¯ä¸ç›®ãƒ‡ãƒ¼ã‚¿ãŒãªã„
                    st.info("â„¹ï¸ ã“ã®å¤§å­—åã«ã¯ä¸ç›®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                else:
                    # ä¸ç›®ååˆ—è‡ªä½“ãŒå­˜åœ¨ã—ãªã„
                    st.info("â„¹ï¸ ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¯ä¸ç›®æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
            
            # å°å­—åé¸æŠï¼ˆå¤§å­—åãŒé¸æŠã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿ï¼‰
            selected_koaza = None
            if selected_oaza is not None:
                koaza_options = get_koaza_options(st.session_state.gdf, selected_oaza, selected_chome)
                
                if koaza_options is not None and len(koaza_options) > 0:
                    # å°å­—é¸æŠè‚¢ãŒã‚ã‚‹å ´åˆ
                    koaza_list_with_none = ["é¸æŠãªã—"] + koaza_options
                    selected_koaza = st.selectbox(
                        "å°å­—åã‚’é¸æŠï¼ˆä»»æ„ï¼‰", 
                        koaza_list_with_none,
                        help="å°å­—ã‚’æŒ‡å®šã™ã‚‹å ´åˆã¯é¸æŠã—ã¦ãã ã•ã„ã€‚æŒ‡å®šã—ãªã„å ´åˆã¯ã€Œé¸æŠãªã—ã€ã®ã¾ã¾ã«ã—ã¦ãã ã•ã„ã€‚"
                    )
                    
                    if selected_koaza == "é¸æŠãªã—":
                        st.info("ğŸ’¡ å°å­—ã‚’æŒ‡å®šã›ãšã«æ¤œç´¢ã—ã¾ã™")
                    else:
                        st.success(f"âœ… å°å­—ã€Œ{selected_koaza}ã€ã‚’æŒ‡å®šã—ã¾ã—ãŸ")
                        
                elif 'å°å­—å' in st.session_state.gdf.columns:
                    # å°å­—ååˆ—ã¯å­˜åœ¨ã™ã‚‹ãŒã€ã“ã®å¤§å­—åï¼ˆä¸ç›®åï¼‰ã«ã¯å°å­—ãƒ‡ãƒ¼ã‚¿ãŒãªã„
                    condition_text = f"å¤§å­—åã€Œ{selected_oaza}ã€"
                    if selected_chome and selected_chome != "é¸æŠãªã—":
                        condition_text += f"ãƒ»ä¸ç›®åã€Œ{selected_chome}ã€"
                    st.info(f"â„¹ï¸ {condition_text}ã«ã¯å°å­—ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                else:
                    # å°å­—ååˆ—è‡ªä½“ãŒå­˜åœ¨ã—ãªã„
                    st.info("â„¹ï¸ ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¯å°å­—æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
            
            # åœ°ç•ªå…¥åŠ›
            chiban = st.text_input("åœ°ç•ªã‚’å…¥åŠ›", value="1174")
            
            # æ¤œç´¢ç¯„å›²ã‚’å›ºå®šå€¤ã«è¨­å®š
            range_m = 61
            
            # æŠ½å‡ºãƒœã‚¿ãƒ³
            if st.button("ğŸš€ ãƒ‡ãƒ¼ã‚¿æŠ½å‡º", type="primary", use_container_width=True):
                if selected_oaza and chiban:
                    # å¿…è¦ãªåˆ—ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                    required_columns = ['å¤§å­—å', 'åœ°ç•ª']
                    missing_columns = [col for col in required_columns if col not in st.session_state.gdf.columns]
                    
                    if missing_columns:
                        st.error(f"âŒ å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing_columns}")
                        st.write("**åˆ©ç”¨å¯èƒ½ãªåˆ—:**", list(st.session_state.gdf.columns))
                    else:
                        with st.spinner("ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºä¸­..."):
                            target_gdf, overlay_gdf, message = extractor.extract_data(
                                st.session_state.gdf, selected_oaza, selected_chome, selected_koaza, chiban, range_m
                            )
                        
                        st.info(message)
                        
                        if target_gdf is not None and overlay_gdf is not None:
                            # çµæœã‚’ä¿å­˜
                            st.session_state.target_gdf = target_gdf
                            st.session_state.overlay_gdf = overlay_gdf
                            
                            # ãƒ•ã‚¡ã‚¤ãƒ«åã®ç”Ÿæˆï¼ˆä¸ç›®ãƒ»å°å­—ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯å«ã‚ã‚‹ï¼‰
                            file_name_parts = [selected_oaza]
                            if selected_chome and selected_chome != "é¸æŠãªã—":
                                file_name_parts.append(selected_chome)
                            if selected_koaza and selected_koaza != "é¸æŠãªã—":
                                file_name_parts.append(selected_koaza)
                            file_name_parts.append(chiban)
                            
                            st.session_state.file_name = "_".join(file_name_parts)
                elif not selected_oaza:
                    st.error("å¤§å­—åã‚’é¸æŠã—ã¦ãã ã•ã„")
                else:
                    st.error("åœ°ç•ªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        
        with col2:
            st.header("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ä¸€è¦§")
            
            # ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æƒ…å ±ï¼ˆWebãƒ•ã‚©ãƒ«ãƒ€æƒ…å ±ã‚’å«ã‚€ï¼‰
            if 'data_source' in st.session_state:
                with st.expander("â„¹ï¸ ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿æƒ…å ±"):
                    st.write(f"**ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹**: {st.session_state.data_source}")
                    if 'current_preset' in st.session_state:
                        st.write(f"**ãƒ—ãƒªã‚»ãƒƒãƒˆ**: {st.session_state.current_preset}")
                    if 'file_info' in st.session_state:
                        st.write(f"**ãƒ•ã‚¡ã‚¤ãƒ«**: {st.session_state.file_info}")
                    if 'current_folder_url' in st.session_state:
                        st.write(f"**ãƒ•ã‚©ãƒ«ãƒ€URL**: {st.session_state.current_folder_url}")
                    
                    if st.session_state.gdf is not None:
                        st.write(f"**ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°**: {len(st.session_state.gdf):,}ä»¶")
                        st.write(f"**ã‚«ãƒ©ãƒ æ•°**: {len(st.session_state.gdf.columns)}å€‹")
                        if st.session_state.gdf.crs:
                            st.write(f"**åº§æ¨™ç³»**: {st.session_state.gdf.crs}")
                        
                        # ä¸ç›®ãƒ»å°å­—ãƒ‡ãƒ¼ã‚¿ã®æœ‰ç„¡ã‚’è¡¨ç¤º
                        if 'ä¸ç›®å' in st.session_state.gdf.columns:
                            chome_count = st.session_state.gdf['ä¸ç›®å'].notna().sum()
                            total_count = len(st.session_state.gdf)
                            st.write(f"**ä¸ç›®ãƒ‡ãƒ¼ã‚¿**: {chome_count}/{total_count}ä»¶ ({chome_count/total_count*100:.1f}%)")
                        
                        if 'å°å­—å' in st.session_state.gdf.columns:
                            koaza_count = st.session_state.gdf['å°å­—å'].notna().sum()
                            total_count = len(st.session_state.gdf)
                            st.write(f"**å°å­—ãƒ‡ãƒ¼ã‚¿**: {koaza_count}/{total_count}ä»¶ ({koaza_count/total_count*100:.1f}%)")
            
            # Webãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰å–å¾—ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã®è¡¨ç¤º
            if 'current_web_files' in st.session_state and st.session_state.current_web_files:
                if st.checkbox("ğŸŒ Webãƒ•ã‚©ãƒ«ãƒ€ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’è¡¨ç¤º"):
                    st.write(f"**ğŸ“‚ {st.session_state.current_folder_url}ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§:**")
                    
                    files_df = pd.DataFrame(st.session_state.current_web_files)
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’æ•´ç†ã—ã¦è¡¨ç¤º
                    display_df = pd.DataFrame({
                        'ãƒ•ã‚¡ã‚¤ãƒ«å': files_df['name'],
                        'èª¬æ˜': files_df['description'],
                        'ã‚µã‚¤ã‚º': files_df['size'].apply(
                            lambda x: f"{x:,} bytes" if x is not None else "ä¸æ˜"
                        )
                    })
                    
                    st.dataframe(display_df, use_container_width=True)
                    
                    # æ›´æ–°ãƒœã‚¿ãƒ³
                    if st.button("ğŸ”„ ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’æ›´æ–°"):
                        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
                        if 'web_files_cache' in st.session_state:
                            st.session_state.web_files_cache.clear()
                        
                        with st.spinner("ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’æ›´æ–°ä¸­..."):
                            new_files = extractor.get_files_from_web_folder(st.session_state.current_folder_url)
                            if new_files:
                                st.session_state.current_web_files = new_files
                                st.success(f"âœ… {len(new_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ã—ã¾ã—ãŸ")
                            else:
                                st.warning("âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            
            # å¤§å­—åãƒ»ä¸ç›®åãƒ»å°å­—åã®ã‚µãƒãƒªãƒ¼
            if st.checkbox("å¤§å­—åãƒ»ä¸ç›®åãƒ»å°å­—åä¸€è¦§ã‚’è¡¨ç¤º"):
                try:
                    if 'å¤§å­—å' in st.session_state.gdf.columns:
                        # NULLå€¤ã‚’é™¤å¤–ã—ã¦é›†è¨ˆ
                        oaza_clean = st.session_state.gdf['å¤§å­—å'].dropna()
                        if len(oaza_clean) > 0:
                            st.write("**å¤§å­—ååˆ¥é›†è¨ˆ:**")
                            oaza_summary = oaza_clean.value_counts()
                            st.dataframe(oaza_summary.head(20), use_container_width=True)
                            
                            # ä¸ç›®åã®é›†è¨ˆã‚‚è¡¨ç¤º
                            if 'ä¸ç›®å' in st.session_state.gdf.columns:
                                chome_clean = st.session_state.gdf['ä¸ç›®å'].dropna()
                                if len(chome_clean) > 0:
                                    st.write("**ä¸ç›®ååˆ¥é›†è¨ˆ:**")
                                    chome_summary = chome_clean.value_counts()
                                    st.dataframe(chome_summary.head(20), use_container_width=True)
                            
                            # å°å­—åã®é›†è¨ˆã‚‚è¡¨ç¤º
                            if 'å°å­—å' in st.session_state.gdf.columns:
                                koaza_clean = st.session_state.gdf['å°å­—å'].dropna()
                                if len(koaza_clean) > 0:
                                    st.write("**å°å­—ååˆ¥é›†è¨ˆ:**")
                                    koaza_summary = koaza_clean.value_counts()
                                    st.dataframe(koaza_summary.head(20), use_container_width=True)
                            
                            # å¤§å­—åÃ—ä¸ç›®åÃ—å°å­—åã®ã‚¯ãƒ­ã‚¹é›†è¨ˆ
                            cross_columns = ['å¤§å­—å']
                            if 'ä¸ç›®å' in st.session_state.gdf.columns:
                                cross_columns.append('ä¸ç›®å')
                            if 'å°å­—å' in st.session_state.gdf.columns:
                                cross_columns.append('å°å­—å')
                            
                            if len(cross_columns) > 1:
                                st.write(f"**{' Ã— '.join(cross_columns)}ã®çµ„ã¿åˆã‚ã›:**")
                                cross_data = st.session_state.gdf.copy()
                                
                                # å„åˆ—ãŒNULLã§ãªã„ãƒ‡ãƒ¼ã‚¿ã®ã¿æŠ½å‡º
                                for col in cross_columns:
                                    cross_data = cross_data[cross_data[col].notna()]
                                
                                if len(cross_data) > 0:
                                    cross_summary = cross_data.groupby(cross_columns).size().reset_index(name='ä»¶æ•°')
                                    cross_summary = cross_summary.sort_values('ä»¶æ•°', ascending=False)
                                    st.dataframe(cross_summary.head(20), use_container_width=True)
                            
                            # NULLå€¤ã®æƒ…å ±ã‚‚è¡¨ç¤º
                            null_info = []
                            for col in ['å¤§å­—å', 'ä¸ç›®å', 'å°å­—å']:
                                if col in st.session_state.gdf.columns:
                                    null_count = st.session_state.gdf[col].isnull().sum()
                                    if null_count > 0:
                                        null_info.append(f"{col}: {null_count}ä»¶")
                            
                            if null_info:
                                st.warning(f"âš ï¸ NULLå€¤: {', '.join(null_info)}")
                        else:
                            st.error("å¤§å­—åãƒ‡ãƒ¼ã‚¿ãŒã™ã¹ã¦NULLã¾ãŸã¯ç©ºã§ã™")
                    else:
                        st.warning("'å¤§å­—å'åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                except Exception as e:
                    st.error(f"ãƒ‡ãƒ¼ã‚¿è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {str(e)}")
            
            # åœ°ç•ªæ¤œç´¢ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
            if st.checkbox("åœ°ç•ªæ¤œç´¢"):
                search_term = st.text_input("åœ°ç•ªã‚’æ¤œç´¢", placeholder="ä¾‹: 1174")
                
                # æ¤œç´¢ã‚ªãƒ—ã‚·ãƒ§ãƒ³
                col_search1, col_search2 = st.columns(2)
                with col_search1:
                    exact_match = st.checkbox("å®Œå…¨ä¸€è‡´", value=False, help="ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã¨å®Œå…¨ä¸€è‡´ã§æ¤œç´¢ã—ã¾ã™")
                with col_search2:
                    show_geometry = st.checkbox("åº§æ¨™æƒ…å ±ã‚’è¡¨ç¤º", value=False, help="æ¤œç´¢çµæœã«åº§æ¨™æƒ…å ±ã‚’å«ã‚ã¾ã™")
                
                if search_term:
                    try:
                        if 'åœ°ç•ª' in st.session_state.gdf.columns:
                            # åœ°ç•ªã‚’stringå‹ã«å¤‰æ›ã—ã¦ã‹ã‚‰æ¤œç´¢ï¼ˆNULLå€¤ã‚‚è€ƒæ…®ï¼‰
                            chiban_str = st.session_state.gdf['åœ°ç•ª'].astype(str)
                            
                            if exact_match:
                                # å®Œå…¨ä¸€è‡´æ¤œç´¢
                                filtered = st.session_state.gdf[
                                    (chiban_str == search_term) & 
                                    (chiban_str != 'nan') & 
                                    (st.session_state.gdf['åœ°ç•ª'].notna())
                                ]
                            else:
                                # éƒ¨åˆ†ä¸€è‡´æ¤œç´¢
                                filtered = st.session_state.gdf[
                                    (chiban_str.str.contains(search_term, na=False)) & 
                                    (chiban_str != 'nan') & 
                                    (st.session_state.gdf['åœ°ç•ª'].notna())
                                ]
                            
                            # è¡¨ç¤ºç”¨ã®åˆ—ã‚’é¸æŠ
                            display_columns = []
                            for col in ['å¤§å­—å', 'ä¸ç›®å', 'å°å­—å', 'åœ°ç•ª']:
                                if col in filtered.columns:
                                    display_columns.append(col)
                            
                            # åº§æ¨™æƒ…å ±ã‚’è¿½åŠ ã™ã‚‹å ´åˆ
                            if show_geometry and 'geometry' in filtered.columns:
                                filtered_with_coords = filtered.copy()
                                filtered_with_coords['ä¸­å¿ƒXåº§æ¨™'] = filtered_with_coords['geometry'].centroid.x
                                filtered_with_coords['ä¸­å¿ƒYåº§æ¨™'] = filtered_with_coords['geometry'].centroid.y
                                display_columns.extend(['ä¸­å¿ƒXåº§æ¨™', 'ä¸­å¿ƒYåº§æ¨™'])
                                filtered = filtered_with_coords
                            
                            if display_columns and len(filtered) > 0:
                                st.write(f"**æ¤œç´¢çµæœ: {len(filtered)}ä»¶**")
                                st.dataframe(
                                    filtered[display_columns].head(50),
                                    use_container_width=True
                                )
                                
                                # æ¤œç´¢çµæœãŒå¤šã„å ´åˆã®è­¦å‘Š
                                if len(filtered) > 50:
                                    st.info(f"â„¹ï¸ çµæœãŒ{len(filtered)}ä»¶ã‚ã‚Šã¾ã™ã€‚æœ€åˆã®50ä»¶ã®ã¿è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚")
                                    
                            elif len(filtered) == 0:
                                st.info(f"'{search_term}'ã«ä¸€è‡´ã™ã‚‹åœ°ç•ªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                            else:
                                st.warning("è¡¨ç¤ºå¯èƒ½ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                        else:
                            st.warning("'åœ°ç•ª'åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    except Exception as e:
                        st.error(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
                        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
                        st.write("åœ°ç•ªåˆ—ã®ãƒ‡ãƒ¼ã‚¿å‹:", st.session_state.gdf['åœ°ç•ª'].dtype)
                        st.write("åœ°ç•ªåˆ—ã®NULLæ•°:", st.session_state.gdf['åœ°ç•ª'].isnull().sum())
            
            # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ç¢ºèª
            if st.checkbox("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ç¢ºèª"):
                try:
                    st.write("**ã‚«ãƒ©ãƒ ä¸€è¦§:**")
                    col_info = pd.DataFrame({
                        'ã‚«ãƒ©ãƒ å': st.session_state.gdf.columns,
                        'ãƒ‡ãƒ¼ã‚¿å‹': st.session_state.gdf.dtypes.astype(str),
                        'éNULLæ•°': st.session_state.gdf.count(),
                        'NULLæ•°': st.session_state.gdf.isnull().sum()
                    })
                    col_info['NULLç‡(%)'] = (col_info['NULLæ•°'] / len(st.session_state.gdf) * 100).round(1)
                    st.dataframe(col_info, use_container_width=True)
                    
                    st.write("**ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ« (æœ€åˆã®5è¡Œ):**")
                    display_df = st.session_state.gdf.head()
                    if 'geometry' in display_df.columns:
                        display_df = display_df.drop(columns=['geometry'])
                    st.dataframe(display_df, use_container_width=True)
                    
                    # çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
                    st.write("**åŸºæœ¬çµ±è¨ˆ:**")
                    stats_info = {
                        'ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°': len(st.session_state.gdf),
                        'åº§æ¨™ç³»': str(st.session_state.gdf.crs) if st.session_state.gdf.crs else 'ä¸æ˜',
                        'å¤§å­—åã®ç¨®é¡æ•°': st.session_state.gdf['å¤§å­—å'].nunique() if 'å¤§å­—å' in st.session_state.gdf.columns else 'ãªã—',
                        'åœ°ç•ªã®ç¨®é¡æ•°': st.session_state.gdf['åœ°ç•ª'].nunique() if 'åœ°ç•ª' in st.session_state.gdf.columns else 'ãªã—'
                    }
                    
                    if 'ä¸ç›®å' in st.session_state.gdf.columns:
                        stats_info['ä¸ç›®åã®ç¨®é¡æ•°'] = st.session_state.gdf['ä¸ç›®å'].nunique()
                        stats_info['ä¸ç›®ãƒ‡ãƒ¼ã‚¿æœ‰ã‚Š'] = st.session_state.gdf['ä¸ç›®å'].notna().sum()
                    
                    if 'å°å­—å' in st.session_state.gdf.columns:
                        stats_info['å°å­—åã®ç¨®é¡æ•°'] = st.session_state.gdf['å°å­—å'].nunique()
                        stats_info['å°å­—ãƒ‡ãƒ¼ã‚¿æœ‰ã‚Š'] = st.session_state.gdf['å°å­—å'].notna().sum()
                    
                    for key, value in stats_info.items():
                        st.write(f"- **{key}**: {value}")
                    
                except Exception as e:
                    st.error(f"ãƒ‡ãƒ¼ã‚¿æ§‹é€ ç¢ºèªã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        # çµæœè¡¨ç¤ºã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        if 'target_gdf' in st.session_state and 'overlay_gdf' in st.session_state:
            st.markdown("---")
            st.header("ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
            
            col3, col4, col5 = st.columns(3)
            
            with col3:
                st.subheader("ğŸ¯ å¯¾è±¡ç­†")
                target_kml = extractor.create_kml_from_geodataframe(
                    st.session_state.target_gdf, 
                    f"{st.session_state.file_name}_å¯¾è±¡ç­†"
                )
                if target_kml:
                    st.download_button(
                        "ğŸ“„ å¯¾è±¡ç­†KMLãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=target_kml,
                        file_name=f"{st.session_state.file_name}_å¯¾è±¡ç­†.kml",
                        mime="application/vnd.google-earth.kml+xml",
                        use_container_width=True
                    )
            
            with col4:
                st.subheader("ğŸ˜ï¸ å‘¨è¾ºç­†")
                overlay_kml = extractor.create_kml_from_geodataframe(
                    st.session_state.overlay_gdf,
                    f"{st.session_state.file_name}_å‘¨è¾ºç­†"
                )
                if overlay_kml:
                    st.download_button(
                        "ğŸ“„ å‘¨è¾ºç­†KMLãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=overlay_kml,
                        file_name=f"{st.session_state.file_name}_å‘¨è¾ºç­†.kml",
                        mime="application/vnd.google-earth.kml+xml",
                        use_container_width=True
                    )
            
            with col5:
                st.subheader("ğŸ“Š CSVå‡ºåŠ›")
                # åº§æ¨™æƒ…å ±ä»˜ãCSV
                csv_data = st.session_state.overlay_gdf.copy()
                csv_data['ä¸­å¿ƒXåº§æ¨™'] = csv_data['geometry'].centroid.x
                csv_data['ä¸­å¿ƒYåº§æ¨™'] = csv_data['geometry'].centroid.y
                csv_export = csv_data.drop(columns=['geometry']).to_csv(index=False, encoding='shift-jis')
                
                st.download_button(
                    "ğŸ“Š å‘¨è¾ºç­†CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=csv_export,
                    file_name=f"{st.session_state.file_name}_å‘¨è¾ºç­†.csv",
                    mime="text/csv",
                    use_container_width=True
                )
            
            # çµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
            st.markdown("---")
            st.header("ğŸ‘€ çµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
            
            tab1, tab2, tab3 = st.tabs(["å¯¾è±¡ç­†", "å‘¨è¾ºç­†", "æ¤œç´¢æ¡ä»¶"])
            
            with tab1:
                if not st.session_state.target_gdf.empty:
                    st.write("**å¯¾è±¡ç­†ã®è©³ç´°æƒ…å ±:**")
                    display_df = st.session_state.target_gdf.drop(columns=['geometry'])
                    st.dataframe(display_df, use_container_width=True)
                    
                    # å¯¾è±¡ç­†ã®åº§æ¨™æƒ…å ±
                    if st.checkbox("å¯¾è±¡ç­†ã®åº§æ¨™æƒ…å ±ã‚’è¡¨ç¤º"):
                        coords_df = st.session_state.target_gdf.copy()
                        coords_df['ä¸­å¿ƒXåº§æ¨™'] = coords_df['geometry'].centroid.x
                        coords_df['ä¸­å¿ƒYåº§æ¨™'] = coords_df['geometry'].centroid.y
                        coords_df['é¢ç©(mÂ²)'] = coords_df['geometry'].area
                        coord_display = coords_df[['ä¸­å¿ƒXåº§æ¨™', 'ä¸­å¿ƒYåº§æ¨™', 'é¢ç©(mÂ²)']]
                        st.dataframe(coord_display, use_container_width=True)
            
            with tab2:
                if not st.session_state.overlay_gdf.empty:
                    st.write(f"**å‘¨è¾ºç­†ä¸€è¦§ ({len(st.session_state.overlay_gdf)}ä»¶):**")
                    display_df = st.session_state.overlay_gdf.drop(columns=['geometry'])
                    st.dataframe(display_df, use_container_width=True)
                    
                    # å‘¨è¾ºç­†ã®çµ±è¨ˆæƒ…å ±
                    if st.checkbox("å‘¨è¾ºç­†ã®çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º"):
                        st.write("**å‘¨è¾ºç­†ã®çµ±è¨ˆ:**")
                        stats_cols = []
                        for col in ['å¤§å­—å', 'ä¸ç›®å', 'å°å­—å', 'åœ°ç•ª']:
                            if col in st.session_state.overlay_gdf.columns:
                                stats_cols.append(col)
                        
                        if stats_cols:
                            for col in stats_cols:
                                if col in st.session_state.overlay_gdf.columns:
                                    unique_count = st.session_state.overlay_gdf[col].nunique()
                                    st.write(f"- **{col}ã®ç¨®é¡æ•°**: {unique_count}")
                        
                        # é¢ç©çµ±è¨ˆ
                        area_stats = st.session_state.overlay_gdf['geometry'].area.describe()
                        st.write("**é¢ç©çµ±è¨ˆ (mÂ²):**")
                        st.dataframe(area_stats.round(2), use_container_width=True)
            
            with tab3:
                st.write("**ä½¿ç”¨ã—ãŸæ¤œç´¢æ¡ä»¶:**")
                search_conditions = {
                    'å¤§å­—å': selected_oaza if 'selected_oaza' in locals() else 'ä¸æ˜',
                    'åœ°ç•ª': chiban if 'chiban' in locals() else 'ä¸æ˜',
                    'æ¤œç´¢ç¯„å›²': "61mï¼ˆå›ºå®šï¼‰"
                }
                
                if 'selected_chome' in locals() and selected_chome and selected_chome != "é¸æŠãªã—":
                    search_conditions['ä¸ç›®å'] = selected_chome
                else:
                    search_conditions['ä¸ç›®å'] = 'æŒ‡å®šãªã—'
                
                if 'selected_koaza' in locals() and selected_koaza and selected_koaza != "é¸æŠãªã—":
                    search_conditions['å°å­—å'] = selected_koaza
                else:
                    search_conditions['å°å­—å'] = 'æŒ‡å®šãªã—'
                
                for key, value in search_conditions.items():
                    st.write(f"- **{key}**: {value}")
                
                # æŠ½å‡ºçµæœã®ã‚µãƒãƒªãƒ¼
                st.write("**æŠ½å‡ºçµæœã‚µãƒãƒªãƒ¼:**")
                result_summary = {
                    'å¯¾è±¡ç­†ä»¶æ•°': len(st.session_state.target_gdf),
                    'å‘¨è¾ºç­†ä»¶æ•°': len(st.session_state.overlay_gdf),
                    'ç·æŠ½å‡ºä»¶æ•°': len(st.session_state.target_gdf) + len(st.session_state.overlay_gdf)
                }
                
                for key, value in result_summary.items():
                    st.write(f"- **{key}**: {value}ä»¶")
    
    else:
        st.info("ğŸ‘† ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’é¸æŠã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„")
        
        # ä½¿ã„æ–¹èª¬æ˜ï¼ˆWebãƒ•ã‚©ãƒ«ãƒ€æ©Ÿèƒ½ã‚’å«ã‚€æ”¹è‰¯ç‰ˆï¼‰
        with st.expander("ğŸ“– ä½¿ã„æ–¹"):
            st.markdown("""
            ### ğŸŒ æ–°æ©Ÿèƒ½: Webãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ã®ãƒ—ãƒªã‚»ãƒƒãƒˆé¸æŠ
            **Webãƒ•ã‚©ãƒ«ãƒ€ãƒ—ãƒªã‚»ãƒƒãƒˆ** ğŸ“‚
            - Webä¸Šã®ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰è¤‡æ•°ã®Shapefileã‚’è‡ªå‹•å–å¾—
            - GitHubãƒ•ã‚©ãƒ«ãƒ€ã€ä¸€èˆ¬çš„ãªWebãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«å¯¾å¿œ
            - ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å‹•çš„ã«è¡¨ç¤ºãƒ»é¸æŠå¯èƒ½
            - ä¾‹: `https://github.com/user/repo/tree/main/data`
            
            **ä½¿ç”¨æ‰‹é †:**
            1. **ã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚©ãƒ«ãƒ€URL**ã‚’å…¥åŠ›ã€ã¾ãŸã¯**ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚©ãƒ«ãƒ€**ã‚’é¸æŠ
            2. **ã€Œãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—ã€**ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
            3. å–å¾—ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‹ã‚‰**ç›®çš„ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ**
            4. **ã€Œé¸æŠãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€**ãƒœã‚¿ãƒ³ã§ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
            
            ### ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ï¼ˆå¾“æ¥æ©Ÿèƒ½ï¼‰
            **1. å›ºå®šãƒ—ãƒªã‚»ãƒƒãƒˆ** ğŸ“‹
            - äº‹å‰è¨­å®šã•ã‚ŒãŸã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«
            
            **2. ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«** ğŸ“
            - SHPãƒ•ã‚¡ã‚¤ãƒ«ä¸€å¼ã‚’ZIPåœ§ç¸®ã—ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            
            **3. Web URL** ğŸŒ
            - ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«ã®URL
            - ä¾‹: `https://example.com/data.zip`
            
            **4. GitHub** ğŸ™
            - GitHubãƒªãƒã‚¸ãƒˆãƒªå†…ã®å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«
            - ãƒ¦ãƒ¼ã‚¶ãƒ¼åã€ãƒªãƒã‚¸ãƒˆãƒªåã€ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æŒ‡å®š
            
            ### ğŸ“‹ æ¤œç´¢æ‰‹é †
            1. **ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹**ã‚’é¸æŠã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            2. **å¤§å­—å**ã‚’ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ã‹ã‚‰é¸æŠ
            3. **ä¸ç›®å**ã‚’é¸æŠï¼ˆä¸ç›®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿è¡¨ç¤ºï¼‰
               - ä¸ç›®ã‚’æŒ‡å®šã—ãŸããªã„å ´åˆã¯ã€Œé¸æŠãªã—ã€ã®ã¾ã¾
            4. **å°å­—å**ã‚’é¸æŠï¼ˆå°å­—ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿è¡¨ç¤ºï¼‰
               - å°å­—ã‚’æŒ‡å®šã—ãŸããªã„å ´åˆã¯ã€Œé¸æŠãªã—ã€ã®ã¾ã¾
            5. **åœ°ç•ª**ã‚’å…¥åŠ›
            6. **æ¤œç´¢ç¯„å›²**ã‚’è¨­å®šï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 61mï¼‰
            7. **ãƒ‡ãƒ¼ã‚¿æŠ½å‡º**ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
            8. **KMLãƒ•ã‚¡ã‚¤ãƒ«**ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            
            ### ğŸ˜ï¸ ä¸ç›®ãƒ»å°å­—æ©Ÿèƒ½ã«ã¤ã„ã¦
            - ãƒ‡ãƒ¼ã‚¿ã«ã€Œä¸ç›®åã€ã€Œå°å­—åã€åˆ—ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã€ãã‚Œãã‚Œã§ã®çµã‚Šè¾¼ã¿ãŒå¯èƒ½
            - å¤§å­—åã‚’é¸æŠã™ã‚‹ã¨ã€ãã®å¤§å­—ã«å¯¾å¿œã™ã‚‹ä¸ç›®ãƒ»å°å­—ã®ã¿ãŒè¡¨ç¤ºã•ã‚Œã¾ã™
            - ä¸ç›®ã‚’é¸æŠã™ã‚‹ã¨ã€ãã®ä¸ç›®ã«å¯¾å¿œã™ã‚‹å°å­—ã®ã¿ãŒè¡¨ç¤ºã•ã‚Œã¾ã™
            - ä¸ç›®ãƒ»å°å­—ã‚’æŒ‡å®šã—ãªã„å ´åˆã¯ã€ä¸Šä½ã®åœ°åŸŸåŒºåˆ†å†…ã®å…¨ã¦ã®ç­†ãŒæ¤œç´¢å¯¾è±¡ã«ãªã‚Šã¾ã™
            
            ### ğŸ¯ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«
            - **å¯¾è±¡ç­†KML**: æŒ‡å®šã—ãŸç­†ã®KMLãƒ•ã‚¡ã‚¤ãƒ«
            - **å‘¨è¾ºç­†KML**: å‘¨è¾ºç­†ã®KMLãƒ•ã‚¡ã‚¤ãƒ«
            - **CSV**: åº§æ¨™æƒ…å ±ä»˜ãã®CSVãƒ•ã‚¡ã‚¤ãƒ«
            
            ### ğŸ—ºï¸ å¯¾å¿œã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢
            - Google Earth
            - Google ãƒã‚¤ãƒãƒƒãƒ—
            - QGIS
            - ãã®ä»–GISã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢
            
            ### ğŸ” æ¤œç´¢ãƒ»åˆ†ææ©Ÿèƒ½
            - **åœ°ç•ªæ¤œç´¢**: å®Œå…¨ä¸€è‡´ãƒ»éƒ¨åˆ†ä¸€è‡´ã§ã®åœ°ç•ªæ¤œç´¢
            - **åº§æ¨™è¡¨ç¤º**: æ¤œç´¢çµæœã«ä¸­å¿ƒåº§æ¨™ã‚’è¡¨ç¤ºå¯èƒ½
            - **ãƒ‡ãƒ¼ã‚¿æ§‹é€ ç¢ºèª**: åˆ—æƒ…å ±ã€NULLå€¤çµ±è¨ˆã€ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
            - **éšå±¤æ¤œç´¢**: å¤§å­—åâ†’ä¸ç›®åâ†’å°å­—åã®éšå±¤ã§ã®çµã‚Šè¾¼ã¿æ¤œç´¢
            - **Webãƒ•ã‚©ãƒ«ãƒ€ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§**: å–å¾—ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°æƒ…å ±è¡¨ç¤º
            - **çµ±è¨ˆæƒ…å ±**: å„åœ°åŸŸåŒºåˆ†ã®ä»¶æ•°ãƒ»å‰²åˆã®ç¢ºèª
            
            ### ğŸ”— å¯¾å¿œURLå½¢å¼
            **Webãƒ•ã‚©ãƒ«ãƒ€:**
            - **GitHubãƒ•ã‚©ãƒ«ãƒ€**: `https://github.com/user/repo/tree/branch/path`
            - **ä¸€èˆ¬Webãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª**: `https://example.com/data/`
            
            **å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«:**
            - **ç›´æ¥URL**: `https://example.com/shapefile.zip`
            - **GitHubå€‹åˆ¥**: `https://github.com/username/repo/blob/main/data.zip`
            - **GitHub Raw**: `https://raw.githubusercontent.com/username/repo/main/data.zip`
            
            ### ğŸ“ åœ°åŸŸåŒºåˆ†ã®éšå±¤
            ```
            å¤§å­—å (å¿…é ˆ)
            â”œâ”€â”€ ä¸ç›®å (ä»»æ„)
            â”‚   â””â”€â”€ å°å­—å (ä»»æ„)
            â””â”€â”€ å°å­—å (ä»»æ„ã€ä¸ç›®ãªã—ã®å ´åˆ)
            ```
            
            ### ğŸ’¡ Webãƒ•ã‚©ãƒ«ãƒ€æ©Ÿèƒ½ã®åˆ©ç‚¹
            - **è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†**: ä¸€ã¤ã®ãƒ•ã‚©ãƒ«ãƒ€ã«è¤‡æ•°ã®Shapefileã‚’é…ç½®ã—ã¦ç®¡ç†
            - **å‹•çš„æ›´æ–°**: ãƒ•ã‚©ãƒ«ãƒ€å†…å®¹ã®å¤‰æ›´ãŒå³åº§ã«åæ˜ 
            - **ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†**: GitHubã‚’ä½¿ç”¨ã—ãŸå ´åˆã€ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ãŒå¯èƒ½
            - **å…±æœ‰**: ãƒãƒ¼ãƒ å†…ã§ã®ãƒ‡ãƒ¼ã‚¿å…±æœ‰ãŒå®¹æ˜“
            - **è‡ªå‹•ç™ºè¦‹**: å¯¾å¿œæ‹¡å¼µå­ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•æ¤œå‡º
            
            ### âš ï¸ GitHub APIåˆ¶é™ã«ã¤ã„ã¦
            - **ãƒ¬ãƒ¼ãƒˆåˆ¶é™**: GitHub APIã¯1æ™‚é–“ã‚ãŸã‚Š60ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®åˆ¶é™ãŒã‚ã‚Šã¾ã™
            - **åˆ¶é™æ™‚ã®å¯¾å‡¦**: åˆ¶é™ã«é”ã—ãŸå ´åˆã€è‡ªå‹•çš„ã«ä»£æ›¿æ–¹æ³•ï¼ˆHTMLã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼‰ã«åˆ‡ã‚Šæ›¿ã‚ã‚Šã¾ã™
            - **ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨**: GitHubãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç’°å¢ƒå¤‰æ•°`GITHUB_TOKEN`ã«è¨­å®šã™ã‚‹ã¨åˆ¶é™ãŒç·©å’Œã•ã‚Œã¾ã™ï¼ˆ5000ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/æ™‚é–“ï¼‰
            - **å¾…æ©Ÿæ™‚é–“**: åˆ¶é™ã«é”ã—ãŸå ´åˆã€1æ™‚é–“å¾…ã£ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„
            
            ### ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
            - **403ã‚¨ãƒ©ãƒ¼**: GitHub APIãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚æ™‚é–“ã‚’ãŠã„ã¦å†è©¦è¡Œã—ã¦ãã ã•ã„
            - **ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„**: ãƒ•ã‚©ãƒ«ãƒ€ã®URLãŒæ­£ã—ã„ã‹ã€ãƒ•ã‚¡ã‚¤ãƒ«ãŒ.zipã¾ãŸã¯.shpå½¢å¼ã‹ç¢ºèªã—ã¦ãã ã•ã„
            - **èªè¨¼ã‚¨ãƒ©ãƒ¼**: ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒªãƒã‚¸ãƒˆãƒªã®å ´åˆã€é©åˆ‡ãªã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒå¿…è¦ã§ã™
            """)

if __name__ == "__main__":
    main()