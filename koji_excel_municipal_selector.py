    # æ¤œç´¢çµæœã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ
    if 'matching_files' in st.session_state and st.session_state.matching_files:
        st.sidebar.write(f"**ğŸ¯ {st.session_state.selected_municipality}ã®å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«:**")
        
        file_options = ["é¸æŠã—ã¦ãã ã•ã„"] + [f["name"] for f in st.session_state.matching_files]
        selected_file = st.sidebar.selectbox(
            "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
            file_options,
            help="èª­ã¿è¾¼ã‚€Shapefileã‚’é¸æŠã—ã¦ãã ã•ã„"
        )
        
        if selected_file != "é¸æŠã—ã¦ãã ã•ã„":
            selected_file_info = next((f for f in st.session_state.matching_files if f["name"] == selected_file), None)
            
            if selected_file_info:
                st.sidebar.info(f"**{selected_file_info['name']}**\n\n{selected_file_info['description']}")
                
                if st.sidebar.button("ğŸ“¥ é¸æŠãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿", type="primary"):
                    try:
                        with st.spinner(f"ãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{selected_file}ã€ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
                            st.session_state.gdf = extractor.load_shapefile_from_url(selected_file_info['url'])
                        
                        st.sidebar.success("âœ… ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†!")
                        st.sidebar.info(f"ğŸ“Š ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(st.session_state.gdf):,}ä»¶")
                        
                        if st.session_state.gdf.crs:
                            st.sidebar.info(f"ğŸ—ºï¸ åº§æ¨™ç³»: {st.session_state.gdf.crs}")
                        
                        # ä¸ç›®åãƒ»å°å­—ååˆ—ã®å­˜åœ¨ç¢ºèª
                        if 'ä¸ç›®å' in st.session_state.gdf.columns:
                            chome_count = st.session_state.gdf['ä¸ç›®å'].notna().sum()
                            st.sidebar.info(f"ğŸ˜ï¸ ä¸ç›®ãƒ‡ãƒ¼ã‚¿: {chome_count}ä»¶")
                        
                        if 'å°å­—å' in st.session_state.gdf.columns:
                            koaza_count = st.session_state.gdf['å°å­—å'].notna().sum()
                            st.sidebar.info(f"ğŸï¸ å°å­—ãƒ‡ãƒ¼ã‚¿: {koaza_count}ä»¶")
                        
                        # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æƒ…å ±ã‚’è¨˜éŒ²
                        st.session_state.data_source = "Excelè‡ªæ²»ä½“é¸æŠ"
                        st.session_state.current_file = selected_file
                        st.session_state.file_url = selected_file_info['url']
                            
                    except Exception as e:
                        st.sidebar.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
    if st.session_state.gdf is not None:
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.header("ğŸ” æ¤œç´¢æ¡ä»¶")
            
            # ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿æƒ…å ±ã‚’è¡¨ç¤º
            if 'selected_municipality' in st.session_state:
                st.info(f"ğŸ“ ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿: {st.session_state.selected_municipality}")
                if 'municipality_code' in st.session_state:
                    st.info(f"ğŸ›ï¸ è‡ªæ²»ä½“ã‚³ãƒ¼ãƒ‰: {st.session_state.municipality_code}")
            
            # å¤§å­—åé¸æŠ
            selected_oaza = None
            try:
                if 'å¤§å­—å' in st.session_state.gdf.columns:
                    oaza_series = st.session_state.gdf['å¤§å­—å'].dropna()
                    if len(oaza_series) > 0:
                        oaza_list = sorted(oaza_series.unique())
                        selected_oaza = st.selectbox("å¤§å­—åã‚’é¸æŠ", oaza_list)
                    else:
                        st.error("âŒ å¤§å­—åãƒ‡ãƒ¼ã‚¿ãŒã™ã¹ã¦NULLã§ã™")
                        selected_oaza = None
                else:
                    st.error("âŒ 'å¤§å­—å'åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                    st.write("**åˆ©ç”¨å¯èƒ½ãªåˆ—:**", list(st.session_state.gdf.columns))
                    selected_oaza = None
            except Exception as e:
                st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
                selected_oaza = None
            
            # ä¸ç›®åé¸æŠ
            selected_chome = None
            if selected_oaza is not None:
                chome_options = get_chome_options(st.session_state.gdf, selected_oaza)
                
                if chome_options is not None and len(chome_options) > 0:
                    chome_list_with_none = ["é¸æŠãªã—"] + chome_options
                    selected_chome = st.selectbox(
                        "ä¸ç›®åã‚’é¸æŠï¼ˆä»»æ„ï¼‰", 
                        chome_list_with_none,
                        help="ä¸ç›®ã‚’æŒ‡å®šã™ã‚‹å ´åˆã¯é¸æŠã—ã¦ãã ã•ã„"
                    )
                    
                    if selected_chome == "é¸æŠãªã—":
                        st.info("ğŸ’¡ ä¸ç›®ã‚’æŒ‡å®šã›ãšã«æ¤œç´¢ã—ã¾ã™")
                    else:
                        st.success(f"âœ… ä¸ç›®ã€Œ{selected_chome}ã€ã‚’æŒ‡å®šã—ã¾ã—ãŸ")
                        
                elif 'ä¸ç›®å' in st.session_state.gdf.columns:
                    st.info("â„¹ï¸ ã“ã®å¤§å­—åã«ã¯ä¸ç›®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                else:
                    st.info("â„¹ï¸ ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¯ä¸ç›®æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
            
            # å°å­—åé¸æŠ
            selected_koaza = None
            if selected_oaza is not None:
                koaza_options = get_koaza_options(st.session_state.gdf, selected_oaza, selected_chome)
                
                if koaza_options is not None and len(koaza_options) > 0:
                    koaza_list_with_none = ["é¸æŠãªã—"] + koaza_options
                    selected_koaza = st.selectbox(
                        "å°å­—åã‚’é¸æŠï¼ˆä»»æ„ï¼‰", 
                        koaza_list_with_none,
                        help="å°å­—ã‚’æŒ‡å®šã™ã‚‹å ´åˆã¯é¸æŠã—ã¦ãã ã•ã„"
                    )
                    
                    if selected_koaza == "é¸æŠãªã—":
                        st.info("ğŸ’¡ å°å­—ã‚’æŒ‡å®šã›ãšã«æ¤œç´¢ã—ã¾ã™")
                    else:
                        st.success(f"âœ… å°å­—ã€Œ{selected_koaza}ã€ã‚’æŒ‡å®šã—ã¾ã—ãŸ")
                        
                elif 'å°å­—å' in st.session_state.gdf.columns:
                    condition_text = f"å¤§å­—åã€Œ{selected_oaza}ã€"
                    if selected_chome and selected_chome != "é¸æŠãªã—":
                        condition_text += f"ãƒ»ä¸ç›®åã€Œ{selected_chome}ã€"
                    st.info(f"â„¹ï¸ {condition_text}ã«ã¯å°å­—ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                else:
                    st.info("â„¹ï¸ ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¯å°å­—æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
            
            # åœ°ç•ªå…¥åŠ›
            chiban = st.text_input("åœ°ç•ªã‚’å…¥åŠ›", value="1174")
            
            # æ¤œç´¢ç¯„å›²
            range_m = 61
            
            # æŠ½å‡ºãƒœã‚¿ãƒ³
            if st.button("ğŸš€ ãƒ‡ãƒ¼ã‚¿æŠ½å‡º", type="primary", use_container_width=True):
                if selected_oaza and chiban:
                    required_columns = ['å¤§å­—å', 'åœ°ç•ª']
                    missing_columns = [col for col in required_columns if col not in st.session_state.gdf.columns]
                    
                    if missing_columns:
                        st.error(f"âŒ å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing_columns}")
                        st.write("**åˆ©ç”¨å¯èƒ½ãªåˆ—:**", list(st.session_state.gdf.columns))
                    else:
                        with st.spinner("ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºä¸­..."):
                            target_gdf, overlay_gdf, message = extractor.extract_data(
                                st.session_state.gdf, selected_oaza, selected_chome, selected_koaza, chiban, range_m
                            )
                        
                        st.info(message)
                        
                        if target_gdf is not None and overlay_gdf is not None:
                            # çµæœã‚’ä¿å­˜
                            st.session_state.target_gdf = target_gdf
                            st.session_state.overlay_gdf = overlay_gdf
                            
                            # ãƒ•ã‚¡ã‚¤ãƒ«åã®ç”Ÿæˆï¼ˆä¸ç›®ãƒ»å°å­—ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯å«ã‚ã‚‹ï¼‰
                            file_name_parts = [selected_oaza]
                            if selected_chome and selected_chome != "é¸æŠãªã—":
                                file_name_parts.append(selected_chome)
                            if selected_koaza and selected_koaza != "é¸æŠãªã—":
                                file_name_parts.append(selected_koaza)
                            file_name_parts.append(chiban)
                            
                            st.session_state.file_name = "_".join(file_name_parts)
                elif not selected_oaza:
                    st.error("å¤§å­—åã‚’é¸æŠã—ã¦ãã ã•ã„")
                else:
                    st.error("åœ°ç•ªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        
        with col2:
            st.header("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ä¸€è¦§")
            
            # ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿æƒ…å ±ã‚’è¡¨ç¤º
            if 'selected_municipality' in st.session_state:
                with st.expander("â„¹ï¸ ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿æƒ…å ±"):
                    st.write(f"**ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹**: Excelè‡ªæ²»ä½“ãƒ‡ãƒ¼ã‚¿é€£æº")
                    st.write(f"**é¸æŠè‡ªæ²»ä½“**: {st.session_state.selected_municipality}")
                    if 'municipality_code' in st.session_state:
                        st.write(f"**è‡ªæ²»ä½“ã‚³ãƒ¼ãƒ‰**: {st.session_state.municipality_code}")
                    if 'current_file' in st.session_state:
                        st.write(f"**èª­ã¿è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«**: {st.session_state.current_file}")
                    
                    if st.session_state.gdf is not None:
                        st.write(f"**ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°**: {len(st.session_state.gdf):,}ä»¶")
                        st.write(f"**ã‚«ãƒ©ãƒ æ•°**: {len(st.session_state.gdf.columns)}å€‹")
                        if st.session_state.gdf.crs:
                            st.write(f"**åº§æ¨™ç³»**: {st.session_state.gdf.crs}")
                        
                        # ä¸ç›®ãƒ»å°å­—ãƒ‡ãƒ¼ã‚¿ã®æœ‰ç„¡ã‚’è¡¨ç¤º
                        if 'ä¸ç›®å' in st.session_state.gdf.columns:
                            chome_count = st.session_state.gdf['ä¸ç›®å'].notna().sum()
                            total_count = len(st.session_state.gdf)
                            st.write(f"**ä¸ç›®ãƒ‡ãƒ¼ã‚¿**: {chome_count}/{total_count}ä»¶ ({chome_count/total_count*100:.1f}%)")
                        
                        if 'å°å­—å' in st.session_state.gdf.columns:
                            koaza_count = st.session_state.gdf['å°å­—å'].notna().sum()
                            total_count = len(st.session_state.gdf)
                            st.write(f"**å°å­—ãƒ‡ãƒ¼ã‚¿**: {koaza_count}/{total_count}ä»¶ ({koaza_count/total_count*100:.1f}%)")
            
            # è‡ªæ²»ä½“ãƒ‡ãƒ¼ã‚¿æƒ…å ±ã®è¡¨ç¤º
            if st.session_state.municipal_data is not None:
                if st.checkbox("ğŸ›ï¸ è‡ªæ²»ä½“ãƒ‡ãƒ¼ã‚¿æƒ…å ±ã‚’è¡¨ç¤º"):
                    st.write("**è‡ªæ²»ä½“ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±:**")
                    st.write(f"- **ç·è‡ªæ²»ä½“æ•°**: {len(st.session_state.municipal_data)}ä»¶")
                    st.write(f"- **éƒ½é“åºœçœŒæ•°**: {st.session_state.municipal_data['éƒ½é“åºœçœŒåï¼ˆæ¼¢å­—ï¼‰'].nunique()}ä»¶")
                    
                    # éƒ½é“åºœçœŒåˆ¥ã®è‡ªæ²»ä½“æ•°
                    prefecture_counts = st.session_state.municipal_data['éƒ½é“åºœçœŒåï¼ˆæ¼¢å­—ï¼‰'].value_counts().head(10)
                    st.write("**éƒ½é“åºœçœŒåˆ¥è‡ªæ²»ä½“æ•°ï¼ˆä¸Šä½10ä½ï¼‰:**")
                    st.dataframe(prefecture_counts, use_container_width=True)
            
            # æ¤œç´¢çµæœãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
            if 'matching_files' in st.session_state and st.session_state.matching_files:
                if st.checkbox("ğŸ—‚ï¸ æ¤œç´¢çµæœãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’è¡¨ç¤º"):
                    st.write(f"**ğŸ¯ {st.session_state.selected_municipality}ã®å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§:**")
                    
                    files_df = pd.DataFrame(st.session_state.matching_files)
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’æ•´ç†ã—ã¦è¡¨ç¤º
                    display_df = pd.DataFrame({
                        'ãƒ•ã‚¡ã‚¤ãƒ«å': files_df['name'],
                        'èª¬æ˜': files_df['description'],
                        'ã‚µã‚¤ã‚º': files_df['size'].apply(
                            lambda x: f"{x:,} bytes" if x is not None else "ä¸æ˜"
                        )
                    })
                    
                    st.dataframe(display_df, use_container_width=True)
            
            # å¤§å­—åãƒ»ä¸ç›®åãƒ»å°å­—åã®ã‚µãƒãƒªãƒ¼
            if st.checkbox("å¤§å­—åãƒ»ä¸ç›®åãƒ»å°å­—åä¸€è¦§ã‚’è¡¨ç¤º"):
                try:
                    if 'å¤§å­—å' in st.session_state.gdf.columns:
                        # NULLå€¤ã‚’é™¤å¤–ã—ã¦é›†è¨ˆ
                        oaza_clean = st.session_state.gdf['å¤§å­—å'].dropna()
                        if len(oaza_clean) > 0:
                            st.write("**å¤§å­—ååˆ¥é›†è¨ˆ:**")
                            oaza_summary = oaza_clean.value_counts()
                            st.dataframe(oaza_summary.head(20), use_container_width=True)
                            
                            # ä¸ç›®åã®é›†è¨ˆã‚‚è¡¨ç¤º
                            if 'ä¸ç›®å' in st.session_state.gdf.columns:
                                chome_clean = st.session_state.gdf['ä¸ç›®å'].dropna()
                                if len(chome_clean) > 0:
                                    st.write("**ä¸ç›®ååˆ¥é›†è¨ˆ:**")
                                    chome_summary = chome_clean.value_counts()
                                    st.dataframe(chome_summary.head(20), use_container_width=True)
                            
                            # å°å­—åã®é›†è¨ˆã‚‚è¡¨ç¤º
                            if 'å°å­—å' in st.session_state.gdf.columns:
                                koaza_clean = st.session_state.gdf['å°å­—å'].dropna()
                                if len(koaza_clean) > 0:
                                    st.write("**å°å­—ååˆ¥é›†è¨ˆ:**")
                                    koaza_summary = koaza_clean.value_counts()
                                    st.dataframe(koaza_summary.head(20), use_container_width=True)
                            
                            # NULLå€¤ã®æƒ…å ±ã‚‚è¡¨ç¤º
                            null_info = []
                            for col in ['å¤§å­—å', 'ä¸ç›®å', 'å°å­—å']:
                                if col in st.session_state.gdf.columns:
                                    null_count = st.session_state.gdf[col].isnull().sum()
                                    if null_count > 0:
                                        null_info.append(f"{col}: {null_count}ä»¶")
                            
                            if null_info:
                                st.warning(f"âš ï¸ NULLå€¤: {', '.join(null_info)}")
                        else:
                            st.error("å¤§å­—åãƒ‡ãƒ¼ã‚¿ãŒã™ã¹ã¦NULLã¾ãŸã¯ç©ºã§ã™")
                    else:
                        st.warning("'å¤§å­—å'åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                except Exception as e:
                    st.error(f"ãƒ‡ãƒ¼ã‚¿è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {str(e)}")
            
            # åœ°ç•ªæ¤œç´¢
            if st.checkbox("åœ°ç•ªæ¤œç´¢"):
                search_term = st.text_input("åœ°ç•ªã‚’æ¤œç´¢", placeholder="ä¾‹: 1174")
                
                # æ¤œç´¢ã‚ªãƒ—ã‚·ãƒ§ãƒ³
                col_search1, col_search2 = st.columns(2)
                with col_search1:
                    exact_match = st.checkbox("å®Œå…¨ä¸€è‡´", value=False, help="ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã¨å®Œå…¨ä¸€è‡´ã§æ¤œç´¢ã—ã¾ã™")
                with col_search2:
                    show_geometry = st.checkbox("åº§æ¨™æƒ…å ±ã‚’è¡¨ç¤º", value=False, help="æ¤œç´¢çµæœã«åº§æ¨™æƒ…å ±ã‚’å«ã‚ã¾ã™")
                
                if search_term:
                    try:
                        if 'åœ°ç•ª' in st.session_state.gdf.columns:
                            # åœ°ç•ªã‚’stringå‹ã«å¤‰æ›ã—ã¦ã‹ã‚‰æ¤œç´¢ï¼ˆNULLå€¤ã‚‚è€ƒæ…®ï¼‰
                            chiban_str = st.session_state.gdf['åœ°ç•ª'].astype(str)
                            
                            if exact_match:
                                # å®Œå…¨ä¸€è‡´æ¤œç´¢
                                filtered = st.session_state.gdf[
                                    (chiban_str == search_term) & 
                                    (chiban_str != 'nan') & 
                                    (st.session_state.gdf['åœ°ç•ª'].notna())
                                ]
                            else:
                                # éƒ¨åˆ†ä¸€è‡´æ¤œç´¢
                                filtered = st.session_state.gdf[
                                    (chiban_str.str.contains(search_term, na=False)) & 
                                    (chiban_str != 'nan') & 
                                    (st.session_state.gdf['åœ°ç•ª'].notna())
                                ]
                            
                            # è¡¨ç¤ºç”¨ã®åˆ—ã‚’é¸æŠ
                            display_columns = []
                            for col in ['å¤§å­—å', 'ä¸ç›®å', 'å°å­—å', 'åœ°ç•ª']:
                                if col in filtered.columns:
                                    display_columns.append(col)
                            
                            # åº§æ¨™æƒ…å ±ã‚’è¿½åŠ ã™ã‚‹å ´åˆ
                            if show_geometry and 'geometry' in filtered.columns:
                                filtered_with_coords = filtered.copy()
                                filtered_with_coords['ä¸­å¿ƒXåº§æ¨™'] = filtered_with_coords['geometry'].centroid.x
                                filtered_with_coords['ä¸­å¿ƒYåº§æ¨™'] = filtered_with_coords['geometry'].centroid.y
                                display_columns.extend(['ä¸­å¿ƒXåº§æ¨™', 'ä¸­å¿ƒYåº§æ¨™'])
                                filtered = filtered_with_coords
                            
                            if display_columns and len(filtered) > 0:
                                st.write(f"**æ¤œç´¢çµæœ: {len(filtered)}ä»¶**")
                                st.dataframe(
                                    filtered[display_columns].head(50),
                                    use_container_width=True
                                )
                                
                                # æ¤œç´¢çµæœãŒå¤šã„å ´åˆã®è­¦å‘Š
                                if len(filtered) > 50:
                                    st.info(f"â„¹ï¸ çµæœãŒ{len(filtered)}ä»¶ã‚ã‚Šã¾ã™ã€‚æœ€åˆã®50ä»¶ã®ã¿è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚")
                                    
                            elif len(filtered) == 0:
                                st.info(f"'{search_term}'ã«ä¸€è‡´ã™ã‚‹åœ°ç•ªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                            else:
                                st.warning("è¡¨ç¤ºå¯èƒ½ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                        else:
                            st.warning("'åœ°ç•ª'åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    except Exception as e:
                        st.error(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
            
            # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ç¢ºèª
            if st.checkbox("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ç¢ºèª"):
                try:
                    st.write("**ã‚«ãƒ©ãƒ ä¸€è¦§:**")
                    col_info = pd.DataFrame({
                        'ã‚«ãƒ©ãƒ å': st.session_state.gdf.columns,
                        'ãƒ‡ãƒ¼ã‚¿å‹': st.session_state.gdf.dtypes.astype(str),
                        'éNULLæ•°': st.session_state.gdf.count(),
                        'NULLæ•°': st.session_state.gdf.isnull().sum()
                    })
                    col_info['NULLç‡(%)'] = (col_info['NULLæ•°'] / len(st.session_state.gdf) * 100).round(1)
                    st.dataframe(col_info, use_container_width=True)
                    
                    st.write("**ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ« (æœ€åˆã®5è¡Œ):**")
                    display_df = st.session_state.gdf.head()
                    if 'geometry' in display_df.columns:
                        display_df = display_df.drop(columns=['geometry'])
                    st.dataframe(display_df, use_container_width=True)
                    
                    # çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
                    st.write("**åŸºæœ¬çµ±è¨ˆ:**")
                    stats_info = {
                        'ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°': len(st.session_state.gdf),
                        'åº§æ¨™ç³»': str(st.session_state.gdf.crs) if st.session_state.gdf.crs else 'ä¸æ˜',
                        'å¤§å­—åã®ç¨®é¡æ•°': st.session_state.gdf['å¤§å­—å'].nunique() if 'å¤§å­—å' in st.session_state.gdf.columns else 'ãªã—',
                        'åœ°ç•ªã®ç¨®é¡æ•°': st.session_state.gdf['åœ°ç•ª'].nunique() if 'åœ°ç•ª' in st.session_state.gdf.columns else 'ãªã—'
                    }
                    
                    if 'ä¸ç›®å' in st.session_state.gdf.columns:
                        stats_info['ä¸ç›®åã®ç¨®é¡æ•°'] = st.session_state.gdf['ä¸ç›®å'].nunique()
                        stats_info['ä¸ç›®ãƒ‡ãƒ¼ã‚¿æœ‰ã‚Š'] = st.session_state.gdf['ä¸ç›®å'].notna().sum()
                    
                    if 'å°å­—å' in st.session_state.gdf.columns:
                        stats_info['å°å­—åã®ç¨®é¡æ•°'] = st.session_state.gdf['å°å­—å'].nunique()
                        stats_info['å°å­—ãƒ‡ãƒ¼ã‚¿æœ‰ã‚Š'] = st.session_state.gdf['å°å­—å'].notna().sum()
                    
                    for key, value in stats_info.items():
                        st.write(f"- **{key}**: {value}")
                    
                except Exception as e:
                    st.error(f"ãƒ‡ãƒ¼ã‚¿æ§‹é€ ç¢ºèªã‚¨ãƒ©ãƒ¼: {str(e)}")
    
        # çµæœè¡¨ç¤ºã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        if 'target_gdf' in st.session_state and 'overlay_gdf' in st.session_state:
            st.markdown("---")
            st.header("ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
            
            col3, col4, col5 = st.columns(3)
            
            with col3:
                st.subheader("ğŸ¯ å¯¾è±¡ç­†")
                target_kml = extractor.create_kml_from_geodataframe(
                    st.session_state.target_gdf, 
                    f"{st.session_state.file_name}_å¯¾è±¡ç­†"
                )
                if target_kml:
                    st.download_button(
                        "ğŸ“„ å¯¾è±¡ç­†KMLãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=target_kml,
                        file_name=f"{st.session_state.file_name}_å¯¾è±¡ç­†.kml",
                        mime="application/vnd.google-earth.kml+xml",
                        use_container_width=True
                    )
            
            with col4:
                st.subheader("ğŸ˜ï¸ å‘¨è¾ºç­†")
                overlay_kml = extractor.create_kml_from_geodataframe(
                    st.session_state.overlay_gdf,
                    f"{st.session_state.file_name}_å‘¨è¾ºç­†"
                )
                if overlay_kml:
                    st.download_button(
                        "ğŸ“„ å‘¨è¾ºç­†KMLãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=overlay_kml,
                        file_name=f"{st.session_state.file_name}_å‘¨è¾ºç­†.kml",
                        mime="application/vnd.google-earth.kml+xml",
                        use_container_width=True
                    )
            
            with col5:
                st.subheader("ğŸ“Š CSVå‡ºåŠ›")
                # åº§æ¨™æƒ…å ±ä»˜ãCSV
                csv_data = st.session_state.overlay_gdf.copy()
                csv_data['ä¸­å¿ƒXåº§æ¨™'] = csv_data['geometry'].centroid.x
                csv_data['ä¸­å¿ƒYåº§æ¨™'] = csv_data['geometry'].centroid.y
                csv_export = csv_data.drop(columns=['geometry']).to_csv(index=False, encoding='shift-jis')
                
                st.download_button(
                    "ğŸ“Š å‘¨è¾ºç­†CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=csv_export,
                    file_name=f"{st.session_state.file_name}_å‘¨è¾ºç­†.csv",
                    mime="text/csv",
                    use_container_width=True
                )
            
            # çµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
            st.markdown("---")
            st.header("ğŸ‘€ çµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
            
            tab1, tab2, tab3 = st.tabs(["å¯¾è±¡ç­†", "å‘¨è¾ºç­†", "æ¤œç´¢æ¡ä»¶"])
            
            with tab1:
                if not st.session_state.target_gdf.empty:
                    st.write("**å¯¾è±¡ç­†ã®è©³ç´°æƒ…å ±:**")
                    display_df = st.session_state.target_gdf.drop(columns=['geometry'])
                    st.dataframe(display_df, use_container_width=True)
                    
                    # å¯¾è±¡ç­†ã®åº§æ¨™æƒ…å ±
                    if st.checkbox("å¯¾è±¡ç­†ã®åº§æ¨™æƒ…å ±ã‚’è¡¨ç¤º"):
                        coords_df = st.session_state.target_gdf.copy()
                        coords_df['ä¸­å¿ƒXåº§æ¨™'] = coords_df['geometry'].centroid.x
                        coords_df['ä¸­å¿ƒYåº§æ¨™'] = coords_df['geometry'].centroid.y
                        coords_df['é¢ç©(mÂ²)'] = coords_df['geometry'].area
                        coord_display = coords_df[['ä¸­å¿ƒXåº§æ¨™', 'ä¸­å¿ƒYåº§æ¨™', 'é¢ç©(mÂ²)']]
                        st.dataframe(coord_display, use_container_width=True)
            
            with tab2:
                if not st.session_state.overlay_gdf.empty:
                    st.write(f"**å‘¨è¾ºç­†ä¸€è¦§ ({len(st.session_state.overlay_gdf)}ä»¶):**")
                    display_df = st.session_state.overlay_gdf.drop(columns=['geometry'])
                    st.dataframe(display_df, use_container_width=True)
                    
                    # å‘¨è¾ºç­†ã®çµ±è¨ˆæƒ…å ±
                    if st.checkbox("å‘¨è¾ºç­†ã®çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º"):
                        st.write("**å‘¨è¾ºç­†ã®çµ±è¨ˆ:**")
                        stats_cols = []
                        for col in ['å¤§å­—å', 'ä¸ç›®å', 'å°å­—å', 'åœ°ç•ª']:
                            if col in st.session_state.overlay_gdf.columns:
                                stats_cols.append(col)
                        
                        if stats_cols:
                            for col in stats_cols:
                                if col in st.session_state.overlay_gdf.columns:
                                    unique_count = st.session_state.overlay_gdf[col].nunique()
                                    st.write(f"- **{col}ã®ç¨®é¡æ•°**: {unique_count}")
                        
                        # é¢ç©çµ±è¨ˆ
                        area_stats = st.session_state.overlay_gdf['geometry'].area.describe()
                        st.write("**é¢ç©çµ±è¨ˆ (mÂ²):**")
                        st.dataframe(area_stats.round(2), use_container_width=True)
            
            with tab3:
                st.write("**ä½¿ç”¨ã—ãŸæ¤œç´¢æ¡ä»¶:**")
                search_conditions = {
                    'è‡ªæ²»ä½“': f"{st.session_state.selected_municipality}ï¼ˆ{st.session_state.municipality_code}ï¼‰" if 'selected_municipality' in st.session_state else 'ä¸æ˜',
                    'å¤§å­—å': selected_oaza if 'selected_oaza' in locals() else 'ä¸æ˜',
                    'åœ°ç•ª': chiban if 'chiban' in locals() else 'ä¸æ˜',
                    'æ¤œç´¢ç¯„å›²': "61mï¼ˆå›ºå®šï¼‰"
                }
                
                if 'selected_chome' in locals() and selected_chome and selected_chome != "é¸æŠãªã—":
                    search_conditions['ä¸ç›®å'] = selected_chome
                else:
                    search_conditions['ä¸ç›®å'] = 'æŒ‡å®šãªã—'
                
                if 'selected_koaza' in locals() and selected_koaza and selected_koaza != "é¸æŠãªã—":
                    search_conditions['å°å­—å'] = selected_koaza
                else:
                    search_conditions['å°å­—å'] = 'æŒ‡å®šãªã—'
                
                for key, value in search_conditions.items():
                    st.write(f"- **{key}**: {value}")
                
                # æŠ½å‡ºçµæœã®ã‚µãƒãƒªãƒ¼
                st.write("**æŠ½å‡ºçµæœã‚µãƒãƒªãƒ¼:**")
                result_summary = {
                    'å¯¾è±¡ç­†ä»¶æ•°': len(st.session_state.target_gdf),
                    'å‘¨è¾ºç­†ä»¶æ•°': len(st.session_state.overlay_gdf),
                    'ç·æŠ½å‡ºä»¶æ•°': len(st.session_state.target_gdf) + len(st.session_state.overlay_gdf)
                }
                
                for key, value in result_summary.items():
                    st.write(f"- **{key}**: {value}ä»¶")
    
    else:
        st.info("ğŸ‘† è‡ªæ²»ä½“ã‚’é¸æŠã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„")
        
        # ä½¿ã„æ–¹èª¬æ˜
        with st.expander("ğŸ“– ä½¿ã„æ–¹"):
            st.markdown("""
            ### ğŸ›ï¸ Excelè‡ªæ²»ä½“ãƒ‡ãƒ¼ã‚¿é€£æºæ©Ÿèƒ½
            **è‡ªå‹•è‡ªæ²»ä½“ã‚³ãƒ¼ãƒ‰å¤‰æ›ã‚·ã‚¹ãƒ†ãƒ ** ğŸ“Š
            - Excelè‡ªæ²»ä½“ãƒ‡ãƒ¼ã‚¿ï¼ˆ000925835.xlsxï¼‰ã‹ã‚‰è‡ªæ²»ä½“æƒ…å ±ã‚’è‡ªå‹•èª­ã¿è¾¼ã¿
            - éƒ½é“åºœçœŒ â†’ å¸‚åŒºç”ºæ‘ã®éšå±¤é¸æŠ
            - è‡ªæ²»ä½“åã‹ã‚‰è‡ªæ²»ä½“ã‚³ãƒ¼ãƒ‰ã¸ã®è‡ªå‹•å¤‰æ›
            - è‡ªæ²»ä½“ã‚³ãƒ¼ãƒ‰ã«åŸºã¥ãè‡ªå‹•ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ãƒ»æŠ½å‡º
            
            **ä½¿ç”¨æ‰‹é †:**
            1. **éƒ½é“åºœçœŒ**ã‚’ãƒ—ãƒ«ãƒ€ã‚¦ãƒ³ã‹ã‚‰é¸æŠ
            2. **è‡ªæ²»ä½“**ã‚’ãƒ—ãƒ«ãƒ€ã‚¦ãƒ³ã‹ã‚‰é¸æŠï¼ˆè‡ªæ²»ä½“ã‚³ãƒ¼ãƒ‰ãŒè‡ªå‹•è¡¨ç¤ºï¼‰
            3. **ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ«ãƒ€URL**ã‚’è¨­å®šï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ä½¿ç”¨å¯èƒ½ï¼‰
            4. **ã€Œè©²å½“ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ã€**ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
            5. æ¤œç´¢ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‹ã‚‰**ç›®çš„ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ**
            6. **ã€Œé¸æŠãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€**ãƒœã‚¿ãƒ³ã§ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
            
            ### ğŸ“‹ æ¤œç´¢ãƒ»æŠ½å‡ºæ‰‹é †
            1. **å¤§å­—å**ã‚’ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ã‹ã‚‰é¸æŠ
            2. **ä¸ç›®å**ã‚’é¸æŠï¼ˆä¸ç›®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿è¡¨ç¤ºï¼‰
               - æŒ‡å®šã—ãªã„å ´åˆã¯ã€Œé¸æŠãªã—ã€ã®ã¾ã¾
            3. **å°å­—å**ã‚’é¸æŠï¼ˆå°å­—ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿è¡¨ç¤ºï¼‰
               - æŒ‡å®šã—ãªã„å ´åˆã¯ã€Œé¸æŠãªã—ã€ã®ã¾ã¾
            4. **åœ°ç•ª**ã‚’å…¥åŠ›ï¼ˆä¾‹: 1174ï¼‰
            5. **ãƒ‡ãƒ¼ã‚¿æŠ½å‡º**ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
            6. **KMLãƒ•ã‚¡ã‚¤ãƒ«**ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            
            ### ğŸ¯ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«
            - **å¯¾è±¡ç­†KML**: æŒ‡å®šã—ãŸç­†ã®KMLãƒ•ã‚¡ã‚¤ãƒ«
            - **å‘¨è¾ºç­†KML**: å‘¨è¾ºç­†ã®KMLãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ61mç¯„å›²å†…ï¼‰
            - **CSV**: åº§æ¨™æƒ…å ±ä»˜ãã®CSVãƒ•ã‚¡ã‚¤ãƒ«
            
            ### ğŸ” æ¤œç´¢ãƒ»åˆ†ææ©Ÿèƒ½
            - **Excelé€£æºè‡ªæ²»ä½“é¸æŠ**: å…¬å¼ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãæ­£ç¢ºãªè‡ªæ²»ä½“é¸æŠ
            - **è‡ªå‹•ãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹**: è‡ªæ²»ä½“ã‚³ãƒ¼ãƒ‰ã«åŸºã¥ããƒ•ã‚¡ã‚¤ãƒ«è‡ªå‹•æ¤œç´¢
            - **éšå±¤åœ°åŸŸé¸æŠ**: å¤§å­—åâ†’ä¸ç›®åâ†’å°å­—åã®éšå±¤é¸æŠ
            - **åœ°ç•ªæ¤œç´¢**: å®Œå…¨ä¸€è‡´ãƒ»éƒ¨åˆ†ä¸€è‡´ã§ã®åœ°ç•ªæ¤œç´¢
            - **åº§æ¨™æƒ…å ±è¡¨ç¤º**: æ¤œç´¢çµæœã«ä¸­å¿ƒåº§æ¨™ã‚’è¡¨ç¤ºå¯èƒ½
            - **çµ±è¨ˆæƒ…å ±**: å„åœ°åŸŸåŒºåˆ†ã®ä»¶æ•°ãƒ»å‰²åˆã®ç¢ºèª
            - **ãƒ‡ãƒ¼ã‚¿æ§‹é€ ç¢ºèª**: åˆ—æƒ…å ±ã€NULLå€¤çµ±è¨ˆã€ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
            
            ### ğŸ—ºï¸ å¯¾å¿œã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢
            - **Google Earth**: KMLãƒ•ã‚¡ã‚¤ãƒ«ç›´æ¥èª­ã¿è¾¼ã¿
            - **Google ãƒã‚¤ãƒãƒƒãƒ—**: KMLãƒ•ã‚¡ã‚¤ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            - **QGIS**: ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹GISã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢
            - **ArcGIS**: å•†ç”¨GISã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢
            - **ãã®ä»–**: KMLå¯¾å¿œã®GISã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢å…¨èˆ¬
            
            ### ğŸ’¡ Excelé€£æºã®åˆ©ç‚¹
            - **æ­£ç¢ºæ€§**: å…¬å¼ã®è‡ªæ²»ä½“ã‚³ãƒ¼ãƒ‰è¡¨ï¼ˆç·å‹™çœãƒ‡ãƒ¼ã‚¿ï¼‰ã«åŸºã¥ãé¸æŠ
            - **åŠ¹ç‡æ€§**: è‡ªæ²»ä½“åã‹ã‚‰è‡ªå‹•ã§ã‚³ãƒ¼ãƒ‰å¤‰æ›ãƒ»ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
            - **ç¶²ç¾…æ€§**: å…¨å›½47éƒ½é“åºœçœŒã€1700+è‡ªæ²»ä½“ã«å¯¾å¿œ
            - **ä¿å®ˆæ€§**: Excelãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°ã«ã‚ˆã‚Šæœ€æ–°ãƒ‡ãƒ¼ã‚¿ã«è‡ªå‹•å¯¾å¿œ
            - **ä¿¡é ¼æ€§**: å›£ä½“ã‚³ãƒ¼ãƒ‰ï¼ˆ6æ¡ï¼‰ã«ã‚ˆã‚‹ç¢ºå®Ÿãªè­˜åˆ¥
            
            ### ğŸ“ å¯¾å¿œãƒ‡ãƒ¼ã‚¿éšå±¤
            ```
            éƒ½é“åºœçœŒï¼ˆ47ä»¶ï¼‰
            â””â”€â”€ å¸‚åŒºç”ºæ‘ï¼ˆ1700+ä»¶ï¼‰
                â””â”€â”€ å¤§å­—åï¼ˆãƒ‡ãƒ¼ã‚¿ä¾å­˜ï¼‰
                    â”œâ”€â”€ ä¸ç›®åï¼ˆä»»æ„ï¼‰
                    â”‚   â””â”€â”€ å°å­—åï¼ˆä»»æ„ï¼‰
                    â””â”€â”€ å°å­—åï¼ˆä»»æ„ã€ä¸ç›®ãªã—ã®å ´åˆï¼‰
                        â””â”€â”€ åœ°ç•ªï¼ˆå¿…é ˆï¼‰
            ```
            
            ### ğŸ”§ ãƒ•ã‚¡ã‚¤ãƒ«å‘½åè¦å‰‡
            - **æ¨å¥¨å½¢å¼**: `[è‡ªæ²»ä½“ã‚³ãƒ¼ãƒ‰]_[åœ°åŸŸå].zip`
            - **ä¾‹**: `472011_é‚£è¦‡å¸‚.zip`ã€`47_æ²–ç¸„çœŒ.zip`
            - **æ¤œç´¢å¯¾è±¡**: ãƒ•ã‚¡ã‚¤ãƒ«åã«è‡ªæ²»ä½“ã‚³ãƒ¼ãƒ‰ï¼ˆ6æ¡ï¼‰ã¾ãŸã¯éƒ½é“åºœçœŒã‚³ãƒ¼ãƒ‰ï¼ˆ2æ¡ï¼‰ã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«
            
            ### âš ï¸ æ³¨æ„äº‹é …
            - **Excel ãƒ•ã‚¡ã‚¤ãƒ«**: 000925835.xlsx ãŒåŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«å¿…è¦
            - **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯**: GitHubç­‰ã‹ã‚‰ã®ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ã«ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šãŒå¿…è¦  
            - **ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼**: ZIPåœ§ç¸®ã•ã‚ŒãŸShapefileã‚»ãƒƒãƒˆã«å¯¾å¿œ
            - **åº§æ¨™ç³»**: è‡ªå‹•ã§WGS84ï¼ˆç·¯åº¦çµŒåº¦ï¼‰ã«å¤‰æ›ã—ã¦KMLå‡ºåŠ›
            
            ### ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
            - **è‡ªæ²»ä½“ãŒè¦‹ã¤ã‹ã‚‰ãªã„**: Excel ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°ã¾ãŸã¯è‡ªæ²»ä½“åã®è¡¨è¨˜ç¢ºèª
            - **ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„**: è‡ªæ²»ä½“ã‚³ãƒ¼ãƒ‰ãŒãƒ•ã‚¡ã‚¤ãƒ«åã«å«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
            - **èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼**: Shapefileã®å½¢å¼ã€ZIPåœ§ç¸®çŠ¶æ…‹ã‚’ç¢ºèª
            - **åº§æ¨™ã‚¨ãƒ©ãƒ¼**: å…ƒãƒ‡ãƒ¼ã‚¿ã®åº§æ¨™å‚ç…§ç³»ï¼ˆCRSï¼‰ã‚’ç¢ºèª
            """)

if __name__ == "__main__":
    main()
            # -*- coding: utf-8 -*-
"""
é›»å­å…¬å›³ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºWebã‚¢ãƒ—ãƒª (Streamlitç‰ˆ) - Excelè‡ªæ²»ä½“ãƒ‡ãƒ¼ã‚¿é€£æºç‰ˆ
"""

import streamlit as st
import geopandas as gpd
import pandas as pd
from shapely.geometry import Point, Polygon, MultiPolygon
import xml.etree.ElementTree as ET
from xml.dom import minidom
import zipfile
import io
import tempfile
import os
import requests
from urllib.parse import urlparse, urljoin
import re
from bs4 import BeautifulSoup
import json

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="é›»å­å…¬å›³ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºãƒ„ãƒ¼ãƒ«",
    page_icon="ğŸ—ºï¸",
    layout="wide"
)

class KojiExcelMunicipalExtractor:
    def __init__(self):
        if 'gdf' not in st.session_state:
            st.session_state.gdf = None
        if 'web_files_cache' not in st.session_state:
            st.session_state.web_files_cache = {}
        if 'municipal_data' not in st.session_state:
            st.session_state.municipal_data = None
    
    def load_municipal_data_from_excel(self, excel_file_path):
        """Excelãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è‡ªæ²»ä½“ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        try:
            # Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            df = pd.read_excel(excel_file_path, sheet_name=0)
            
            # åˆ—åã‚’æ­£è¦åŒ–ï¼ˆæ”¹è¡Œæ–‡å­—ã‚’é™¤å»ï¼‰
            df.columns = df.columns.str.replace('\r\n', '').str.replace('\n', '')
            
            # å¿…è¦ãªåˆ—ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            required_columns = ['å›£ä½“ã‚³ãƒ¼ãƒ‰', 'éƒ½é“åºœçœŒåï¼ˆæ¼¢å­—ï¼‰', 'å¸‚åŒºç”ºæ‘åï¼ˆæ¼¢å­—ï¼‰']
            missing_columns = [col for col in required_columns if col not in df.columns]
            
            if missing_columns:
                st.error(f"å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing_columns}")
                st.write("åˆ©ç”¨å¯èƒ½ãªåˆ—:", df.columns.tolist())
                return None
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
            df = df.dropna(subset=['å›£ä½“ã‚³ãƒ¼ãƒ‰'])
            df['å›£ä½“ã‚³ãƒ¼ãƒ‰'] = df['å›£ä½“ã‚³ãƒ¼ãƒ‰'].astype(str).str.zfill(6)
            
            # å¸‚åŒºç”ºæ‘åãŒNULLã®è¡Œã‚’é™¤å¤–ï¼ˆéƒ½é“åºœçœŒãƒ¬ãƒ™ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚’é™¤å¤–ï¼‰
            df = df.dropna(subset=['å¸‚åŒºç”ºæ‘åï¼ˆæ¼¢å­—ï¼‰'])
            
            # éƒ½é“åºœçœŒåã¨å¸‚åŒºç”ºæ‘åã‚’çµåˆã—ã¦å®Œå…¨ãªè‡ªæ²»ä½“åã‚’ä½œæˆ
            df['å®Œå…¨è‡ªæ²»ä½“å'] = df['éƒ½é“åºœçœŒåï¼ˆæ¼¢å­—ï¼‰'] + df['å¸‚åŒºç”ºæ‘åï¼ˆæ¼¢å­—ï¼‰']
            
            return df
            
        except Exception as e:
            st.error(f"Excelãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def get_prefectures_from_excel(self, municipal_df):
        """Excelãƒ‡ãƒ¼ã‚¿ã‹ã‚‰éƒ½é“åºœçœŒä¸€è¦§ã‚’å–å¾—"""
        if municipal_df is None:
            return []
        
        try:
            prefectures = sorted(municipal_df['éƒ½é“åºœçœŒåï¼ˆæ¼¢å­—ï¼‰'].dropna().unique())
            return prefectures
        except Exception as e:
            st.error(f"éƒ½é“åºœçœŒä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def get_municipalities_by_prefecture_from_excel(self, municipal_df, prefecture_name):
        """Excelãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æŒ‡å®šéƒ½é“åºœçœŒã®è‡ªæ²»ä½“ä¸€è¦§ã‚’å–å¾—"""
        if municipal_df is None:
            return []
        
        try:
            filtered_df = municipal_df[municipal_df['éƒ½é“åºœçœŒåï¼ˆæ¼¢å­—ï¼‰'] == prefecture_name]
            municipalities = sorted(filtered_df['å¸‚åŒºç”ºæ‘åï¼ˆæ¼¢å­—ï¼‰'].dropna().unique())
            return municipalities
        except Exception as e:
            st.error(f"è‡ªæ²»ä½“ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def get_municipality_code_from_excel(self, municipal_df, prefecture_name, municipality_name):
        """Excelãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è‡ªæ²»ä½“ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—"""
        if municipal_df is None:
            return None
        
        try:
            filtered_df = municipal_df[
                (municipal_df['éƒ½é“åºœçœŒåï¼ˆæ¼¢å­—ï¼‰'] == prefecture_name) &
                (municipal_df['å¸‚åŒºç”ºæ‘åï¼ˆæ¼¢å­—ï¼‰'] == municipality_name)
            ]
            
            if len(filtered_df) > 0:
                return filtered_df.iloc[0]['å›£ä½“ã‚³ãƒ¼ãƒ‰']
            else:
                return None
        except Exception as e:
            st.error(f"è‡ªæ²»ä½“ã‚³ãƒ¼ãƒ‰å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def search_municipality_files(self, folder_url, municipality_code, file_extensions=None):
        """è‡ªæ²»ä½“ã‚³ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
        if file_extensions is None:
            file_extensions = ['.zip', '.shp']
        
        try:
            # ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
            all_files = self.get_files_from_web_folder(folder_url, file_extensions)
            
            # è‡ªæ²»ä½“ã‚³ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            matching_files = []
            
            for file_info in all_files:
                file_name = file_info['name'].lower()
                
                # è‡ªæ²»ä½“ã‚³ãƒ¼ãƒ‰ãŒãƒ•ã‚¡ã‚¤ãƒ«åã«å«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                if str(municipality_code) in file_name:
                    matching_files.append(file_info)
                    continue
                
                # è‡ªæ²»ä½“ã‚³ãƒ¼ãƒ‰ã®æœ€åˆã®2æ¡ï¼ˆéƒ½é“åºœçœŒã‚³ãƒ¼ãƒ‰ï¼‰ã‚‚ãƒã‚§ãƒƒã‚¯
                prefecture_code = str(municipality_code)[:2]
                if prefecture_code in file_name:
                    matching_files.append(file_info)
            
            return matching_files
            
        except Exception as e:
            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def get_files_from_web_folder(self, folder_url, file_extensions=None):
        """Webä¸Šã®ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—"""
        if file_extensions is None:
            file_extensions = ['.zip', '.shp']
        
        try:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒã‚§ãƒƒã‚¯
            cache_key = f"{folder_url}_{','.join(file_extensions)}"
            if cache_key in st.session_state.web_files_cache:
                return st.session_state.web_files_cache[cache_key]
            
            # GitHubã®ãƒ•ã‚©ãƒ«ãƒ€ã®å ´åˆ
            if 'github.com' in folder_url:
                return self._get_github_folder_files(folder_url, file_extensions)
            
            # é€šå¸¸ã®Webãƒ•ã‚©ãƒ«ãƒ€ã®å ´åˆ
            return self._get_generic_web_folder_files(folder_url, file_extensions)
            
        except Exception as e:
            st.error(f"ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ã®ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
            return []
    
    def _get_github_folder_files(self, folder_url, file_extensions):
        """GitHubãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—ï¼ˆGitHub APIä½¿ç”¨ + ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ï¼‰"""
        try:
            # GitHub URLã‚’è§£æ
            parts = folder_url.replace('https://github.com/', '').split('/')
            if len(parts) < 2:
                raise Exception("ç„¡åŠ¹ãªGitHub URLã§ã™")
            
            user = parts[0]
            repo = parts[1]
            
            # ãƒ–ãƒ©ãƒ³ãƒã¨ãƒ‘ã‚¹ã‚’ç‰¹å®š
            if len(parts) > 3 and parts[2] == 'tree':
                branch = parts[3]
                path = '/'.join(parts[4:]) if len(parts) > 4 else ''
            else:
                branch = 'main'
                path = '/'.join(parts[2:]) if len(parts) > 2 else ''
            
            # ã¾ãšAPIã‚’è©¦è¡Œã—ã€å¤±æ•—ã—ãŸå ´åˆã¯ä»£æ›¿æ–¹æ³•ã‚’ä½¿ç”¨
            try:
                # GitHub API URLæ§‹ç¯‰
                api_url = f"https://api.github.com/repos/{user}/{repo}/contents/{path}"
                if branch != 'main':
                    api_url += f"?ref={branch}"
                
                # GitHub APIãƒˆãƒ¼ã‚¯ãƒ³ãŒã‚ã‚‹å ´åˆã¯ä½¿ç”¨
                headers = {}
                github_token = os.environ.get('GITHUB_TOKEN')
                if github_token:
                    headers['Authorization'] = f'token {github_token}'
                
                response = requests.get(api_url, headers=headers, timeout=30)
                
                if response.status_code == 403:
                    # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®å ´åˆã€ä»£æ›¿æ–¹æ³•ã‚’ä½¿ç”¨
                    st.warning("âš ï¸ GitHub APIã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚ä»£æ›¿æ–¹æ³•ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ã—ã¾ã™...")
                    return self._get_github_files_alternative(user, repo, branch, path, file_extensions)
                
                response.raise_for_status()
                
                files_data = response.json()
                files = []
                
                for item in files_data:
                    if item['type'] == 'file':
                        file_name = item['name']
                        if any(file_name.lower().endswith(ext.lower()) for ext in file_extensions):
                            raw_url = item['download_url']
                            files.append({
                                'name': file_name,
                                'url': raw_url,
                                'size': item.get('size', 0),
                                'description': f"GitHubãƒ•ã‚¡ã‚¤ãƒ« ({item.get('size', 0)} bytes)"
                            })
                
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
                cache_key = f"{folder_url}_{','.join(file_extensions)}"
                st.session_state.web_files_cache[cache_key] = files
                
                return files
                
            except requests.exceptions.RequestException as e:
                if "403" in str(e) or "rate limit" in str(e).lower():
                    st.warning("âš ï¸ GitHub APIã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚ä»£æ›¿æ–¹æ³•ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ã—ã¾ã™...")
                    return self._get_github_files_alternative(user, repo, branch, path, file_extensions)
                else:
                    raise e
                
        except Exception as e:
            raise Exception(f"GitHubå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def _get_github_files_alternative(self, user, repo, branch, path, file_extensions):
        """GitHub APIãŒä½¿ãˆãªã„å ´åˆã®ä»£æ›¿æ–¹æ³•"""
        try:
            web_url = f"https://github.com/{user}/{repo}/tree/{branch}/{path}"
            
            response = requests.get(web_url, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            files = []
            
            # GitHubã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒªãƒ³ã‚¯ã‚’æ¤œç´¢
            file_links = soup.find_all('a', href=True)
            
            for link in file_links:
                href = link.get('href', '')
                link_text = link.get_text().strip()
                
                if '/blob/' in href and any(link_text.lower().endswith(ext.lower()) for ext in file_extensions):
                    raw_url = f"https://raw.githubusercontent.com{href.replace('/blob/', '/')}"
                    
                    files.append({
                        'name': link_text,
                        'url': raw_url,
                        'size': None,
                        'description': f"GitHubãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆä»£æ›¿å–å¾—ï¼‰"
                    })
            
            # é‡è¤‡é™¤å»
            seen_names = set()
            unique_files = []
            for file_info in files:
                if file_info['name'] not in seen_names:
                    seen_names.add(file_info['name'])
                    unique_files.append(file_info)
            
            return unique_files
            
        except Exception as e:
            raise Exception(f"GitHubä»£æ›¿å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def _get_generic_web_folder_files(self, folder_url, file_extensions):
        """ä¸€èˆ¬çš„ãªWebãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—"""
        try:
            response = requests.get(folder_url, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            files = []
            
            links = soup.find_all('a', href=True)
            
            for link in links:
                href = link['href']
                link_text = link.get_text().strip()
                
                if not href.startswith(('http://', 'https://')):
                    href = urljoin(folder_url, href)
                
                if any(href.lower().endswith(ext.lower()) for ext in file_extensions):
                    file_name = os.path.basename(urlparse(href).path)
                    if not file_name:
                        file_name = link_text
                    
                    files.append({
                        'name': file_name,
                        'url': href,
                        'size': None,
                        'description': f"Webãƒ•ã‚¡ã‚¤ãƒ«"
                    })
            
            return files
            
        except Exception as e:
            raise Exception(f"Webãƒ•ã‚©ãƒ«ãƒ€å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def download_file_from_url(self, url):
        """URLã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        try:
            if 'github.com' in url and '/blob/' in url:
                url = url.replace('github.com', 'raw.githubusercontent.com').replace('/blob/', '/')
            
            response = requests.get(url, timeout=30)
            response.raise_for_status()
            
            return io.BytesIO(response.content)
            
        except requests.exceptions.RequestException as e:
            raise Exception(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
    
    def load_shapefile_from_url(self, url):
        """URLã‹ã‚‰Shapefileã‚’èª­ã¿è¾¼ã¿"""
        try:
            file_obj = self.download_file_from_url(url)
            
            with tempfile.TemporaryDirectory() as temp_dir:
                try:
                    with zipfile.ZipFile(file_obj, 'r') as zip_ref:
                        zip_ref.extractall(temp_dir)
                    
                    shp_files = [f for f in os.listdir(temp_dir) if f.endswith('.shp')]
                    
                    if shp_files:
                        shp_path = os.path.join(temp_dir, shp_files[0])
                        return gpd.read_file(shp_path)
                    else:
                        raise Exception("ZIPãƒ•ã‚¡ã‚¤ãƒ«å†…ã«SHPãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                        
                except zipfile.BadZipFile:
                    file_obj.seek(0)
                    temp_file = os.path.join(temp_dir, "temp_file")
                    with open(temp_file, 'wb') as f:
                        f.write(file_obj.read())
                    
                    if url.lower().endswith('.shp'):
                        shp_file = temp_file + '.shp'
                        os.rename(temp_file, shp_file)
                        return gpd.read_file(shp_file)
                    else:
                        return gpd.read_file(temp_file)
                        
        except Exception as e:
            raise Exception(f"Shapefileã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
    
    def create_kml_from_geodataframe(self, gdf, name="åœ°ç•ªãƒ‡ãƒ¼ã‚¿"):
        """GeoPandasãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰KMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        try:
            gdf_wgs84 = gdf.to_crs(epsg=4326)
            
            kml = ET.Element("kml", xmlns="http://www.opengis.net/kml/2.2")
            document = ET.SubElement(kml, "Document")
            doc_name = ET.SubElement(document, "name")
            doc_name.text = name
            
            style = ET.SubElement(document, "Style", id="PolygonStyle")
            line_style = ET.SubElement(style, "LineStyle")
            line_color = ET.SubElement(line_style, "color")
            line_color.text = "ff0000ff"
            line_width = ET.SubElement(line_style, "width")
            line_width.text = "2"
            
            poly_style = ET.SubElement(style, "PolyStyle")
            poly_color = ET.SubElement(poly_style, "color")
            poly_color.text = "3300ff00"
            
            for idx, row in gdf_wgs84.iterrows():
                placemark = ET.SubElement(document, "Placemark")
                
                pm_name = ET.SubElement(placemark, "name")
                if 'åœ°ç•ª' in row:
                    pm_name.text = str(row['åœ°ç•ª'])
                else:
                    pm_name.text = f"åœ°ç•ª_{idx}"
                
                description = ET.SubElement(placemark, "description")
                desc_text = ""
                for col in gdf_wgs84.columns:
                    if col != 'geometry':
                        desc_text += f"{col}: {row[col]}<br/>"
                description.text = desc_text
                
                style_url = ET.SubElement(placemark, "styleUrl")
                style_url.text = "#PolygonStyle"
                
                geom = row['geometry']
                if geom.geom_type == 'Polygon':
                    self._add_polygon_to_placemark(placemark, geom)
                elif geom.geom_type == 'MultiPolygon':
                    for poly in geom.geoms:
                        self._add_polygon_to_placemark(placemark, poly)
                elif geom.geom_type == 'Point':
                    self._add_point_to_placemark(placemark, geom)
            
            rough_string = ET.tostring(kml, 'unicode')
            reparsed = minidom.parseString(rough_string)
            pretty_xml = reparsed.toprettyxml(indent="  ")
            
            return pretty_xml
            
        except Exception as e:
            st.error(f"KMLä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def _add_polygon_to_placemark(self, placemark, polygon):
        """Polygonã‚’Placemarkã«è¿½åŠ """
        multigeometry = placemark.find("MultiGeometry")
        if multigeometry is None:
            multigeometry = ET.SubElement(placemark, "MultiGeometry")
        
        kml_polygon = ET.SubElement(multigeometry, "Polygon")
        
        outer_boundary = ET.SubElement(kml_polygon, "outerBoundaryIs")
        linear_ring = ET.SubElement(outer_boundary, "LinearRing")
        coordinates = ET.SubElement(linear_ring, "coordinates")
        
        coord_str = ""
        for x, y in polygon.exterior.coords:
            coord_str += f"{x},{y},0 "
        coordinates.text = coord_str.strip()
        
        for interior in polygon.interiors:
            inner_boundary = ET.SubElement(kml_polygon, "innerBoundaryIs")
            inner_ring = ET.SubElement(inner_boundary, "LinearRing")
            inner_coordinates = ET.SubElement(inner_ring, "coordinates")
            
            inner_coord_str = ""
            for x, y in interior.coords:
                inner_coord_str += f"{x},{y},0 "
            inner_coordinates.text = inner_coord_str.strip()
    
    def _add_point_to_placemark(self, placemark, point):
        """Pointã‚’Placemarkã«è¿½åŠ """
        kml_point = ET.SubElement(placemark, "Point")
        coordinates = ET.SubElement(kml_point, "coordinates")
        coordinates.text = f"{point.x},{point.y},0"
    
    def extract_data(self, gdf, oaza, chome, koaza, chiban, range_m):
        """ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºå‡¦ç†"""
        try:
            required_columns = ['å¤§å­—å', 'åœ°ç•ª']
            missing_columns = [col for col in required_columns if col not in gdf.columns]
            
            if missing_columns:
                return None, None, f"å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing_columns}"
            
            search_condition = (
                (gdf['å¤§å­—å'] == oaza) & 
                (gdf['åœ°ç•ª'] == chiban) &
                (gdf['å¤§å­—å'].notna()) &
                (gdf['åœ°ç•ª'].notna())
            )
            
            if chome is not None and chome != "é¸æŠãªã—" and 'ä¸ç›®å' in gdf.columns:
                search_condition = search_condition & (gdf['ä¸ç›®å'] == chome) & (gdf['ä¸ç›®å'].notna())
            
            if koaza is not None and koaza != "é¸æŠãªã—" and 'å°å­—å' in gdf.columns:
                search_condition = search_condition & (gdf['å°å­—å'] == koaza) & (gdf['å°å­—å'].notna())
            
            df = gdf[search_condition]
            
            if df.empty:
                return None, None, f"è©²å½“ã™ã‚‹ç­†ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
            
            # ä¸­å¿ƒç‚¹è¨ˆç®—ã¨å‘¨è¾ºç­†æŠ½å‡º
            cen = df.geometry.centroid
            cen_gdf = gpd.GeoDataFrame(geometry=cen)
            cen_gdf['x'] = cen_gdf.geometry.x
            cen_gdf['y'] = cen_gdf.geometry.y
            
            i1 = cen_gdf['x'] + range_m
            i2 = cen_gdf['x'] - range_m
            i3 = cen_gdf['y'] + range_m
            i4 = cen_gdf['y'] - range_m
            
            x1, y1 = i3.iloc[0], i1.iloc[0]
            x2, y2 = i4.iloc[0], i2.iloc[0]
            
            points = pd.DataFrame([
                [x1, y1], [x2, y2], [x1, y2], [x2, y1]
            ], columns=["lon", "lat"])
            
            geometry = [Point(xy) for xy in zip(points.lat, points.lon)]
            four_points_gdf = gpd.GeoDataFrame(points, geometry=geometry)
            sq = four_points_gdf.dissolve().convex_hull
            
            df1 = gpd.GeoDataFrame({'geometry': sq})
            df1 = df1.set_crs(gdf.crs)
            
            valid_data = gdf[(gdf['åœ°ç•ª'].notna()) & (gdf['geometry'].notna())].copy()
            overlay_gdf = df1.overlay(valid_data, how='intersection')
            
            return df, overlay_gdf, f"å¯¾è±¡ç­†: {len(df)}ä»¶, å‘¨è¾ºç­†: {len(overlay_gdf)}ä»¶"
            
        except Exception as e:
            return None, None, f"ã‚¨ãƒ©ãƒ¼: {str(e)}")

def get_chome_options(gdf, selected_oaza):
    """æŒ‡å®šã•ã‚ŒãŸå¤§å­—åã«å¯¾å¿œã™ã‚‹ä¸ç›®ã®é¸æŠè‚¢ã‚’å–å¾—"""
    try:
        if 'ä¸ç›®å' not in gdf.columns:
            return None
        
        filtered_gdf = gdf[
            (gdf['å¤§å­—å'] == selected_oaza) & 
            (gdf['å¤§å­—å'].notna()) &
            (gdf['ä¸ç›®å'].notna())
        ]
        
        if len(filtered_gdf) == 0:
            return None
        
        chome_list = sorted(filtered_gdf['ä¸ç›®å'].unique())
        return chome_list
        
    except Exception as e:
        st.error(f"ä¸ç›®åå–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None

def get_koaza_options(gdf, selected_oaza, selected_chome=None):
    """æŒ‡å®šã•ã‚ŒãŸå¤§å­—åï¼ˆåŠã³ä¸ç›®åï¼‰ã«å¯¾å¿œã™ã‚‹å°å­—ã®é¸æŠè‚¢ã‚’å–å¾—"""
    try:
        if 'å°å­—å' not in gdf.columns:
            return None
        
        filter_condition = (
            (gdf['å¤§å­—å'] == selected_oaza) & 
            (gdf['å¤§å­—å'].notna()) &
            (gdf['å°å­—å'].notna())
        )
        
        if selected_chome and selected_chome != "é¸æŠãªã—" and 'ä¸ç›®å' in gdf.columns:
            filter_condition = filter_condition & (gdf['ä¸ç›®å'] == selected_chome) & (gdf['ä¸ç›®å'].notna())
        
        filtered_gdf = gdf[filter_condition]
        
        if len(filtered_gdf) == 0:
            return None
        
        koaza_list = sorted(filtered_gdf['å°å­—å'].unique())
        return koaza_list
        
    except Exception as e:
        st.error(f"å°å­—åå–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None

def main():
    st.title("ğŸ—ºï¸ é›»å­å…¬å›³ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºãƒ„ãƒ¼ãƒ«ï¼ˆExcelè‡ªæ²»ä½“ãƒ‡ãƒ¼ã‚¿é€£æºç‰ˆï¼‰")
    st.markdown("---")
    
    extractor = KojiExcelMunicipalExtractor()
    
    # Excelãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è‡ªæ²»ä½“ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    excel_file_path = "000925835.xlsx"  # Excelãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    
    if st.session_state.municipal_data is None:
        with st.spinner("è‡ªæ²»ä½“ãƒ‡ãƒ¼ã‚¿ã‚’åˆæœŸåŒ–ä¸­..."):
            st.session_state.municipal_data = extractor.load_municipal_data_from_excel(excel_file_path)
            
            if st.session_state.municipal_data is not None:
                st.success(f"âœ… è‡ªæ²»ä½“ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼ˆ{len(st.session_state.municipal_data)}ä»¶ï¼‰")
            else:
                st.error("âŒ è‡ªæ²»ä½“ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    st.sidebar.header("ğŸ›ï¸ è‡ªæ²»ä½“é¸æŠ")
    
    if st.session_state.municipal_data is not None:
        # éƒ½é“åºœçœŒé¸æŠ
        prefectures = extractor.get_prefectures_from_excel(st.session_state.municipal_data)
        selected_prefecture = st.sidebar.selectbox(
            "éƒ½é“åºœçœŒã‚’é¸æŠ",
            ["é¸æŠã—ã¦ãã ã•ã„"] + prefectures,
            help="ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ãŸã„éƒ½é“åºœçœŒã‚’é¸æŠã—ã¦ãã ã•ã„"
        )
        
        # è‡ªæ²»ä½“é¸æŠ
        selected_municipality = None
        municipality_code = None
        
        if selected_prefecture and selected_prefecture != "é¸æŠã—ã¦ãã ã•ã„":
            municipalities = extractor.get_municipalities_by_prefecture_from_excel(
                st.session_state.municipal_data, selected_prefecture
            )
            
            if municipalities:
                selected_municipality = st.sidebar.selectbox(
                    "è‡ªæ²»ä½“ã‚’é¸æŠ",
                    ["é¸æŠã—ã¦ãã ã•ã„"] + municipalities,
                    help="ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ãŸã„è‡ªæ²»ä½“ã‚’é¸æŠã—ã¦ãã ã•ã„"
                )
                
                if selected_municipality and selected_municipality != "é¸æŠã—ã¦ãã ã•ã„":
                    municipality_code = extractor.get_municipality_code_from_excel(
                        st.session_state.municipal_data, selected_prefecture, selected_municipality
                    )
                    
                    if municipality_code:
                        st.sidebar.success(f"âœ… è‡ªæ²»ä½“ã‚³ãƒ¼ãƒ‰: {municipality_code}")
                        st.sidebar.info(f"ğŸ“ é¸æŠ: {selected_prefecture} {selected_municipality}")
                    else:
                        st.sidebar.error("âŒ è‡ªæ²»ä½“ã‚³ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            else:
                st.sidebar.warning("è©²å½“ã™ã‚‹è‡ªæ²»ä½“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    else:
        st.sidebar.error("âŒ è‡ªæ²»ä½“ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
    
    st.sidebar.markdown("---")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ«ãƒ€è¨­å®š
    st.sidebar.header("ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ«ãƒ€è¨­å®š")
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ«ãƒ€URL
    default_data_folder = "https://github.com/kentashimoji/koji-data-extractor/tree/main"
    
    data_folder_url = st.sidebar.text_input(
        "ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ«ãƒ€URL",
        value=default_data_folder,
        help="ShapefileãŒæ ¼ç´ã•ã‚Œã¦ã„ã‚‹ãƒ•ã‚©ãƒ«ãƒ€ã®URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
    )
    
    # è‡ªæ²»ä½“ã‚³ãƒ¼ãƒ‰ã«åŸºã¥ããƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
    matching_files = []
    if municipality_code and data_folder_url:
        if st.sidebar.button("ğŸ” è©²å½“ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢", type="primary"):
            with st.spinner(f"{selected_municipality}ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ä¸­..."):
                try:
                    matching_files = extractor.search_municipality_files(
                        data_folder_url, 
                        municipality_code
                    )
                    
                    if matching_files:
                        st.sidebar.success(f"âœ… {len(matching_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                        st.session_state.matching_files = matching_files
                        st.session_state.selected_municipality = selected_municipality
                        st.session_state.municipality_code = municipality_code
                    else:
                        st.sidebar.warning(f"âŒ {selected_municipality}ï¼ˆã‚³ãƒ¼ãƒ‰: {municipality_code}ï¼‰ã«è©²å½“ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                
                except Exception as e:
                    st.sidebar.error(f"âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    # æ¤œç´¢çµæœã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ
    if 'matching_files'